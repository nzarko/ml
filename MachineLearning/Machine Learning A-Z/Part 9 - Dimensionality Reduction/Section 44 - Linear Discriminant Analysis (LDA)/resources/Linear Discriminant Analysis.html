<!DOCTYPE html>
<html><head>
  <meta http-equiv="Content-Security-Policy" content="default-src chrome:; img-src data: *; media-src *">
  <meta content="text/html; charset=UTF-8" http-equiv="content-type">
  <meta name="viewport" content="width=device-width; user-scalable=0">
  <link rel="stylesheet" href="chrome://global/skin/aboutReader.css" type="text/css">
  <script type="text/javascript" src="chrome://global/content/reader/aboutReader.js"></script>
<link rel="stylesheet" href="chrome://global/skin/narrate.css"><title>Linear Discriminant Analysis</title><link rel="shortcut icon" href="https://sebastianraschka.com/favicon.ico"></head>

<body class="light sans-serif loaded">
  <div class="container font-size5 content-width3">
    <div class="header reader-header reader-show-element">
      <a class="domain reader-domain" href="https://sebastianraschka.com/Articles/2014_python_lda.html">sebastianraschka.com</a>
      <div class="domain-border"></div>
      <h1 class="reader-title">Linear Discriminant Analysis</h1>
      <div class="credits reader-credits"></div>
      <div class="meta-data">
        <div class="reader-estimated-time">31-40 minutes</div>
      </div>
    </div>

    <hr>

    <div class="content">
      <div class="moz-reader-content line-height4 reader-show-element"><div id="readability-page-1" class="page"><div>
      <div>
        

<div>
  

  <article>
    <h3 id="sections">Sections<a href="#sections" aria-label="Anchor link for: sections" data-anchorjs-icon=""></a></h3>

<ul id="markdown-toc">
  <li><a href="#sections" id="markdown-toc-sections">Sections</a></li>
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a>    <ul>
      <li><a href="#principal-component-analysis-vs-linear-discriminant-analysis" id="markdown-toc-principal-component-analysis-vs-linear-discriminant-analysis">Principal Component Analysis vs. Linear Discriminant Analysis</a></li>
      <li><a href="#what-is-a-good-feature-subspace" id="markdown-toc-what-is-a-good-feature-subspace">What is a “good” feature subspace?</a></li>
      <li><a href="#summarizing-the-lda-approach-in-5-steps" id="markdown-toc-summarizing-the-lda-approach-in-5-steps">Summarizing the LDA approach in 5 steps</a></li>
    </ul>
  </li>
  <li><a href="#preparing-the-sample-data-set" id="markdown-toc-preparing-the-sample-data-set">Preparing the sample data set</a>    <ul>
      <li><a href="#about-the-iris-dataset" id="markdown-toc-about-the-iris-dataset">About the Iris dataset</a></li>
      <li><a href="#reading-in-the-dataset" id="markdown-toc-reading-in-the-dataset">Reading in the dataset</a></li>
      <li><a href="#histograms-and-feature-selection" id="markdown-toc-histograms-and-feature-selection">Histograms and feature selection</a></li>
      <li><a href="#normality-assumptions" id="markdown-toc-normality-assumptions">Normality assumptions</a></li>
    </ul>
  </li>
  <li><a href="#lda-in-5-steps" id="markdown-toc-lda-in-5-steps">LDA in 5 steps</a>    <ul>
      <li><a href="#step-1-computing-the-d-dimensional-mean-vectors" id="markdown-toc-step-1-computing-the-d-dimensional-mean-vectors">Step 1: Computing the d-dimensional mean vectors</a></li>
      <li><a href="#step-2-computing-the-scatter-matrices" id="markdown-toc-step-2-computing-the-scatter-matrices">Step 2: Computing the Scatter Matrices</a>        <ul>
          <li><a href="#21-within-class-scatter-matrix-s_w" id="markdown-toc-21-within-class-scatter-matrix-s_w">2.1 Within-class scatter matrix <span id="MathJax-Element-1-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1"><span><span><span id="MathJax-Span-2"><span id="MathJax-Span-3"><span><span><span id="MathJax-Span-4">S<span></span></span><span></span></span><span><span id="MathJax-Span-5">W<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>W</mi></msub></math></span></span></a></li>
          <li><a href="#21-b" id="markdown-toc-21-b">2.1 b</a></li>
          <li><a href="#22-between-class-scatter-matrix-s_b" id="markdown-toc-22-between-class-scatter-matrix-s_b">2.2 Between-class scatter matrix <span id="MathJax-Element-2-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-6"><span><span><span id="MathJax-Span-7"><span id="MathJax-Span-8"><span><span><span id="MathJax-Span-9">S<span></span></span><span></span></span><span><span id="MathJax-Span-10">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>B</mi></msub></math></span></span></a></li>
        </ul>
      </li>
      <li><a href="#step-3-solving-the-generalized-eigenvalue-problem-for-the-matrix-s_w-1s_b" id="markdown-toc-step-3-solving-the-generalized-eigenvalue-problem-for-the-matrix-s_w-1s_b">Step 3: Solving the generalized eigenvalue problem for the matrix <span id="MathJax-Element-3-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-11"><span><span><span id="MathJax-Span-12"><span id="MathJax-Span-13"><span><span><span id="MathJax-Span-14">S<span></span></span><span></span></span><span><span id="MathJax-Span-15"><span id="MathJax-Span-16"><span id="MathJax-Span-17">−</span><span id="MathJax-Span-18">1</span></span></span><span></span></span><span><span id="MathJax-Span-19"><span id="MathJax-Span-20"><span id="MathJax-Span-21">W<span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-22"><span><span><span id="MathJax-Span-23">S<span></span></span><span></span></span><span><span id="MathJax-Span-24">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>S</mi><mrow><mi>W</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>S</mi><mi>B</mi></msub></math></span></span></a>        <ul>
          <li><a href="#checking-the-eigenvector-eigenvalue-calculation" id="markdown-toc-checking-the-eigenvector-eigenvalue-calculation">Checking the eigenvector-eigenvalue calculation</a></li>
        </ul>
      </li>
      <li><a href="#step-4-selecting-linear-discriminants-for-the-new-feature-subspace" id="markdown-toc-step-4-selecting-linear-discriminants-for-the-new-feature-subspace">Step 4: Selecting linear discriminants for the new feature subspace</a>        <ul>
          <li><a href="#41-sorting-the-eigenvectors-by-decreasing-eigenvalues" id="markdown-toc-41-sorting-the-eigenvectors-by-decreasing-eigenvalues">4.1. Sorting the eigenvectors by decreasing eigenvalues</a></li>
          <li><a href="#42-choosing-k-eigenvectors-with-the-largest-eigenvalues" id="markdown-toc-42-choosing-k-eigenvectors-with-the-largest-eigenvalues">4.2. Choosing <em>k</em> eigenvectors with the largest eigenvalues</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#step-5-transforming-the-samples-onto-the-new-subspace" id="markdown-toc-step-5-transforming-the-samples-onto-the-new-subspace">Step 5: Transforming the samples onto the new subspace</a></li>
  <li><a href="#a-comparison-of-pca-and-lda" id="markdown-toc-a-comparison-of-pca-and-lda">A comparison of PCA and LDA</a></li>
  <li><a href="#lda-via-scikit-learn" id="markdown-toc-lda-via-scikit-learn">LDA via scikit-learn</a></li>
  <li><a href="#a-note-about-standardization" id="markdown-toc-a-note-about-standardization">A Note About Standardization</a></li>
</ul>

<h2 id="introduction">Introduction<a href="#introduction" aria-label="Anchor link for: introduction" data-anchorjs-icon=""></a></h2>

<p>Linear Discriminant Analysis (LDA) is most commonly used as 
dimensionality reduction technique in the pre-processing step for 
pattern-classification and machine learning applications.
The goal is to project a dataset onto a lower-dimensional space with 
good class-separability in order avoid overfitting (“curse of 
dimensionality”) and also reduce computational costs.</p>

<p>Ronald A. Fisher formulated the <em>Linear Discriminant</em> in 1936 (<a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/abstract">The Use of Multiple  Measurements in Taxonomic Problems</a>),
 and it also has some practical uses as classifier. The original Linear 
discriminant was described for a 2-class problem, and it was then later 
generalized as “multi-class Linear Discriminant Analysis” or “Multiple 
Discriminant Analysis” by C. R. Rao in 1948 (<a href="http://www.jstor.org/stable/2983775">The utilization of multiple measurements in problems of biological classification</a>)</p>

<p><strong>The general LDA approach is very similar to a Principal 
Component Analysis (for more information about the PCA, see the previous
 article <a href="http://sebastianraschka.com/Articles/2014_pca_step_by_step.html">Implementing a Principal Component Analysis (PCA) in Python step by step</a>),
 but in addition to finding the component axes that maximize the 
variance of our data (PCA), we are additionally interested in the axes 
that maximize the separation between multiple classes (LDA).</strong></p>

<p>So, in a nutshell, often the goal of an LDA is to project a feature 
space (a dataset n-dimensional samples) onto a smaller subspace <span id="MathJax-Element-4-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-25"><span><span><span id="MathJax-Span-26"><span id="MathJax-Span-27">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span> (where <span id="MathJax-Element-5-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2264;&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-28"><span><span><span id="MathJax-Span-29"><span id="MathJax-Span-30">k</span><span id="MathJax-Span-31">≤</span><span id="MathJax-Span-32">n</span><span id="MathJax-Span-33">−</span><span id="MathJax-Span-34">1</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>≤</mo><mi>n</mi><mo>−</mo><mn>1</mn></math></span></span>) while maintaining the class-discriminatory information. <br>
In general, dimensionality reduction does not only help reducing 
computational costs for a given classification task, but it can also be 
helpful to avoid overfitting by minimizing the error in parameter 
estimation (“curse of dimensionality”).</p>

<h3 id="principal-component-analysis-vs-linear-discriminant-analysis">Principal Component Analysis vs. Linear Discriminant Analysis<a href="#principal-component-analysis-vs-linear-discriminant-analysis" aria-label="Anchor link for: principal component analysis vs linear discriminant analysis" data-anchorjs-icon=""></a></h3>

<p>Both Linear Discriminant Analysis (LDA) and Principal Component 
Analysis (PCA) are linear transformation techniques that are commonly 
used for dimensionality reduction. PCA can be described as an 
“unsupervised” algorithm, since it “ignores” class labels and its goal 
is to find the directions (the so-called principal components) that 
maximize the variance in a dataset.
In contrast to PCA, LDA is “supervised” and computes the directions 
(“linear discriminants”) that  will represent the axes that that 
maximize the separation between multiple classes.</p>

<p>Although it might sound intuitive that LDA is superior to PCA for a 
multi-class classification task where the class labels are known, this 
might not always the case.<br>
For example, comparisons between classification accuracies for image 
recognition after using PCA or LDA show that PCA tends to outperform LDA
 if the number of samples per class is relatively small (<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=908974">PCA vs. LDA</a>,
 A.M. Martinez et al., 2001).
In practice, it is also not uncommon to use both LDA and PCA in 
combination: E.g., PCA for dimensionality reduction followed by an LDA.</p>

<p><img src="Linear%20Discriminant%20Analysis_files/lda_1_002.png" alt="" moz-reader-center="true"></p>

<h3 id="what-is-a-good-feature-subspace">What is a “good” feature subspace?<a href="#what-is-a-good-feature-subspace" aria-label="Anchor link for: what is a good feature subspace" data-anchorjs-icon=""></a></h3>

<p>Let’s assume that our goal is to reduce the dimensions of a <span id="MathJax-Element-6-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-35"><span><span><span id="MathJax-Span-36"><span id="MathJax-Span-37">d<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span>-dimensional dataset by projecting it onto a <span id="MathJax-Element-7-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-38"><span><span><span id="MathJax-Span-39"><span id="MathJax-Span-40">(</span><span id="MathJax-Span-41">k</span><span id="MathJax-Span-42">)</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></math></span></span>-dimensional subspace (where <span id="MathJax-Element-8-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-43"><span><span><span id="MathJax-Span-44"><span id="MathJax-Span-45">k</span><span id="MathJax-Span-46"></span><span id="MathJax-Span-47">&lt;</span><span id="MathJax-Span-48"></span><span id="MathJax-Span-49">d<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mspace width="thickmathspace"></mspace><mo>&lt;</mo><mspace width="thickmathspace"></mspace><mi>d</mi></math></span></span>).
So, how do we know what size we should choose for <span id="MathJax-Element-9-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-50"><span><span><span id="MathJax-Span-51"><span id="MathJax-Span-52">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span> (<span id="MathJax-Element-10-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-53"><span><span><span id="MathJax-Span-54"><span id="MathJax-Span-55">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span>
 = the number of dimensions of the new feature subspace), and how do we 
know if we have a feature space that represents our data “well”?</p>

<p>Later, we will compute eigenvectors (the components) from our data 
set and collect them in a so-called scatter-matrices (i.e., the 
in-between-class scatter matrix and within-class scatter matrix).<br>
Each of these eigenvectors is associated with an eigenvalue, which tells
 us about the “length” or “magnitude” of the eigenvectors.</p>

<p>If we would observe that all eigenvalues have a similar magnitude, 
then this may be a good indicator that our data is already projected on a
 “good” feature space.</p>

<p>And in the other scenario, if some of the eigenvalues are much much 
larger than others, we might be interested in keeping only those 
eigenvectors with the highest eigenvalues, since they contain more 
information about our data distribution. Vice versa, eigenvalues that 
are close to 0 are less informative and we might consider dropping those
 for constructing the new feature subspace.</p>

<h3 id="summarizing-the-lda-approach-in-5-steps">Summarizing the LDA approach in 5 steps<a href="#summarizing-the-lda-approach-in-5-steps" aria-label="Anchor link for: summarizing the lda approach in 5 steps" data-anchorjs-icon=""></a></h3>

<p>Listed below are the 5 general steps for performing a linear 
discriminant analysis; we will explore them in more detail in the 
following sections.</p>

<ol>
  <li>Compute the <span id="MathJax-Element-11-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-56"><span><span><span id="MathJax-Span-57"><span id="MathJax-Span-58">d<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span>-dimensional mean vectors for the different classes from the dataset.</li>
  <li>Compute the scatter matrices (in-between-class and within-class scatter matrix).</li>
  <li>Compute the eigenvectors (<span id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-59"><span><span><span id="MathJax-Span-60"><span id="MathJax-Span-61"><span id="MathJax-Span-62"><span id="MathJax-Span-63"><span><span><span id="MathJax-Span-64"><span id="MathJax-Span-65">e</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-66"></span><span id="MathJax-Span-67"><span><span><span id="MathJax-Span-68"><span id="MathJax-Span-69"><span id="MathJax-Span-70">e</span></span></span><span></span></span><span><span id="MathJax-Span-71">1</span><span></span></span></span></span><span id="MathJax-Span-72">,</span><span id="MathJax-Span-73"></span><span id="MathJax-Span-74"><span id="MathJax-Span-75"><span id="MathJax-Span-76"><span><span><span id="MathJax-Span-77"><span id="MathJax-Span-78">e</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-79"></span><span id="MathJax-Span-80"><span><span><span id="MathJax-Span-81"><span id="MathJax-Span-82"><span id="MathJax-Span-83">e</span></span></span><span></span></span><span><span id="MathJax-Span-84">2</span><span></span></span></span></span><span id="MathJax-Span-85">,</span><span id="MathJax-Span-86"></span><span id="MathJax-Span-87">.</span><span id="MathJax-Span-88">.</span><span id="MathJax-Span-89">.</span><span id="MathJax-Span-90">,</span><span id="MathJax-Span-91"></span><span id="MathJax-Span-92"><span id="MathJax-Span-93"><span id="MathJax-Span-94"><span><span><span id="MathJax-Span-95"><span id="MathJax-Span-96">e</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-97"></span><span id="MathJax-Span-98"><span><span><span id="MathJax-Span-99"><span id="MathJax-Span-100"><span id="MathJax-Span-101">e</span></span></span><span></span></span><span><span id="MathJax-Span-102">d<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>e</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>e</mi></mrow><mn>1</mn></msub><mo>,</mo><mspace width="thickmathspace"></mspace><mrow><mpadded width="0"><mi>e</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>e</mi></mrow><mn>2</mn></msub><mo>,</mo><mspace width="thickmathspace"></mspace><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><mspace width="thickmathspace"></mspace><mrow><mpadded width="0"><mi>e</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>e</mi></mrow><mi>d</mi></msub></math></span></span>) and corresponding eigenvalues (<span id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-103"><span><span><span id="MathJax-Span-104"><span id="MathJax-Span-105"><span id="MathJax-Span-106"><span id="MathJax-Span-107"><span><span><span id="MathJax-Span-108"><span id="MathJax-Span-109">λ</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-110"></span><span id="MathJax-Span-111"><span><span><span id="MathJax-Span-112"><span id="MathJax-Span-113"><span id="MathJax-Span-114">λ</span></span></span><span></span></span><span><span id="MathJax-Span-115">1</span><span></span></span></span></span><span id="MathJax-Span-116">,</span><span id="MathJax-Span-117"></span><span id="MathJax-Span-118"><span id="MathJax-Span-119"><span id="MathJax-Span-120"><span><span><span id="MathJax-Span-121"><span id="MathJax-Span-122">λ</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-123"></span><span id="MathJax-Span-124"><span><span><span id="MathJax-Span-125"><span id="MathJax-Span-126"><span id="MathJax-Span-127">λ</span></span></span><span></span></span><span><span id="MathJax-Span-128">2</span><span></span></span></span></span><span id="MathJax-Span-129">,</span><span id="MathJax-Span-130"></span><span id="MathJax-Span-131">.</span><span id="MathJax-Span-132">.</span><span id="MathJax-Span-133">.</span><span id="MathJax-Span-134">,</span><span id="MathJax-Span-135"></span><span id="MathJax-Span-136"><span id="MathJax-Span-137"><span id="MathJax-Span-138"><span><span><span id="MathJax-Span-139"><span id="MathJax-Span-140">λ</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-141"></span><span id="MathJax-Span-142"><span><span><span id="MathJax-Span-143"><span id="MathJax-Span-144"><span id="MathJax-Span-145">λ</span></span></span><span></span></span><span><span id="MathJax-Span-146">d<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>λ</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>λ</mi></mrow><mn>1</mn></msub><mo>,</mo><mspace width="thickmathspace"></mspace><mrow><mpadded width="0"><mi>λ</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>λ</mi></mrow><mn>2</mn></msub><mo>,</mo><mspace width="thickmathspace"></mspace><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><mspace width="thickmathspace"></mspace><mrow><mpadded width="0"><mi>λ</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>λ</mi></mrow><mi>d</mi></msub></math></span></span>) for the scatter matrices.</li>
  <li>Sort the eigenvectors by decreasing eigenvalues and choose <span id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-147"><span><span><span id="MathJax-Span-148"><span id="MathJax-Span-149">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span> eigenvectors with the largest eigenvalues to form a <span id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-150"><span><span><span id="MathJax-Span-151"><span id="MathJax-Span-152">d<span></span></span><span id="MathJax-Span-153">×</span><span id="MathJax-Span-154">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mo>×</mo><mi>k</mi></math></span></span> dimensional matrix <span id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-155"><span><span><span id="MathJax-Span-156"><span id="MathJax-Span-157"><span id="MathJax-Span-158"><span id="MathJax-Span-159"><span><span><span id="MathJax-Span-160"><span id="MathJax-Span-161">W<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-162"></span><span id="MathJax-Span-163"><span id="MathJax-Span-164"><span id="MathJax-Span-165">W<span></span></span></span></span><span id="MathJax-Span-166"></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>W</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>W</mi></mrow><mspace width="thickmathspace"></mspace></math></span></span> (where every column represents an eigenvector).</li>
  <li>Use this <span id="MathJax-Element-17-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-167"><span><span><span id="MathJax-Span-168"><span id="MathJax-Span-169">d<span></span></span><span id="MathJax-Span-170">×</span><span id="MathJax-Span-171">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mo>×</mo><mi>k</mi></math></span></span> eigenvector matrix to transform the samples onto the new subspace. This can be summarized by the matrix multiplication: <span id="MathJax-Element-18-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-172"><span><span><span id="MathJax-Span-173"><span id="MathJax-Span-174"><span id="MathJax-Span-175"><span id="MathJax-Span-176"><span><span><span id="MathJax-Span-177"><span id="MathJax-Span-178">Y<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-179"></span><span id="MathJax-Span-180"><span id="MathJax-Span-181"><span id="MathJax-Span-182">Y<span></span></span></span></span><span id="MathJax-Span-183">=</span><span id="MathJax-Span-184"><span id="MathJax-Span-185"><span id="MathJax-Span-186"><span><span><span id="MathJax-Span-187"><span id="MathJax-Span-188">X<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-189"></span><span id="MathJax-Span-190"><span id="MathJax-Span-191"><span id="MathJax-Span-192">X<span></span></span></span></span><span id="MathJax-Span-193">×</span><span id="MathJax-Span-194"><span id="MathJax-Span-195"><span id="MathJax-Span-196"><span><span><span id="MathJax-Span-197"><span id="MathJax-Span-198">W<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-199"></span><span id="MathJax-Span-200"><span id="MathJax-Span-201"><span id="MathJax-Span-202">W<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>Y</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>Y</mi></mrow><mo>=</mo><mrow><mpadded width="0"><mi>X</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>X</mi></mrow><mo>×</mo><mrow><mpadded width="0"><mi>W</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>W</mi></mrow></math></span></span> (where <span id="MathJax-Element-19-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-203"><span><span><span id="MathJax-Span-204"><span id="MathJax-Span-205"><span id="MathJax-Span-206"><span id="MathJax-Span-207"><span><span><span id="MathJax-Span-208"><span id="MathJax-Span-209">X<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-210"></span><span id="MathJax-Span-211"><span id="MathJax-Span-212"><span id="MathJax-Span-213">X<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>X</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>X</mi></mrow></math></span></span> is a <span id="MathJax-Element-20-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-214"><span><span><span id="MathJax-Span-215"><span id="MathJax-Span-216">n</span><span id="MathJax-Span-217">×</span><span id="MathJax-Span-218">d<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>×</mo><mi>d</mi></math></span></span>-dimensional matrix representing the <span id="MathJax-Element-21-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-219"><span><span><span id="MathJax-Span-220"><span id="MathJax-Span-221">n</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span> samples, and <span id="MathJax-Element-22-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-222"><span><span><span id="MathJax-Span-223"><span id="MathJax-Span-224"><span id="MathJax-Span-225"><span id="MathJax-Span-226"><span><span><span id="MathJax-Span-227"><span id="MathJax-Span-228">y<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-229"></span><span id="MathJax-Span-230"><span id="MathJax-Span-231"><span id="MathJax-Span-232">y<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>y</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>y</mi></mrow></math></span></span> are the transformed <span id="MathJax-Element-23-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-233"><span><span><span id="MathJax-Span-234"><span id="MathJax-Span-235">n</span><span id="MathJax-Span-236">×</span><span id="MathJax-Span-237">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>×</mo><mi>k</mi></math></span></span>-dimensional samples in the new subspace).</li>
</ol>



<h2 id="preparing-the-sample-data-set">Preparing the sample data set<a href="#preparing-the-sample-data-set" aria-label="Anchor link for: preparing the sample data set" data-anchorjs-icon=""></a></h2>



<h3 id="about-the-iris-dataset">About the Iris dataset<a href="#about-the-iris-dataset" aria-label="Anchor link for: about the iris dataset" data-anchorjs-icon=""></a></h3>

<p>For the following tutorial, we will be working with the famous “Iris”
 dataset that has been deposited on the UCI machine learning repository<br>
(https://archive.ics.uci.edu/ml/datasets/Iris).</p>

<span size="1">
**Reference:**
Bache, K. &amp; Lichman, M. (2013). UCI Machine Learning Repository. 
Irvine, CA: University of California, School of Information and Computer
 Science.</span>

<p>The iris dataset contains measurements for 150 iris flowers from  three different species.</p>

<p>The three classes in the Iris dataset:</p>

<ol>
  <li>Iris-setosa (n=50)</li>
  <li>Iris-versicolor (n=50)</li>
  <li>Iris-virginica (n=50)</li>
</ol>

<p>The four features of the Iris dataset:</p>

<ol>
  <li>sepal length in cm</li>
  <li>sepal width in cm</li>
  <li>petal length in cm</li>
  <li>petal width in cm</li>
</ol>

<p><img src="Linear%20Discriminant%20Analysis_files/iris_petal_sepal.png" alt=""></p>

<div><div><pre><code><span>feature_dict</span> <span>=</span> <span>{</span><span>i</span><span>:</span><span>label</span> <span>for</span> <span>i</span><span>,</span><span>label</span> <span>in</span> <span>zip</span><span>(</span>
                <span>range</span><span>(</span><span>4</span><span>),</span>
                  <span>(</span><span>'sepal length in cm'</span><span>,</span>
                  <span>'sepal width in cm'</span><span>,</span>
                  <span>'petal length in cm'</span><span>,</span>
                  <span>'petal width in cm'</span><span>,</span> <span>))}</span>
</code></pre></div></div>



<h3 id="reading-in-the-dataset">Reading in the dataset<a href="#reading-in-the-dataset" aria-label="Anchor link for: reading in the dataset" data-anchorjs-icon=""></a></h3>

<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>io</span><span>.</span><span>parsers</span><span>.</span><span>read_csv</span><span>(</span>
    <span>filepath_or_buffer</span><span>=</span><span>'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'</span><span>,</span>
    <span>header</span><span>=</span><span>None</span><span>,</span>
    <span>sep</span><span>=</span><span>','</span><span>,</span>
    <span>)</span>
<span>df</span><span>.</span><span>columns</span> <span>=</span> <span>[</span><span>l</span> <span>for</span> <span>i</span><span>,</span><span>l</span> <span>in</span> <span>sorted</span><span>(</span><span>feature_dict</span><span>.</span><span>items</span><span>())]</span> <span>+</span> <span>[</span><span>'class label'</span><span>]</span>
<span>df</span><span>.</span><span>dropna</span><span>(</span><span>how</span><span>=</span><span>"all"</span><span>,</span> <span>inplace</span><span>=</span><span>True</span><span>)</span> <span># to drop the empty line at file-end</span>

<span>df</span><span>.</span><span>tail</span><span>()</span>
</code></pre></div></div>

<div>
<table>
  <thead>
    <tr>
      <th></th>
      <th>sepal length in cm</th>
      <th>sepal width in cm</th>
      <th>petal length in cm</th>
      <th>petal width in cm</th>
      <th>class label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>145</th>
      <td>6.7</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>146</th>
      <td>6.3</td>
      <td>2.5</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>147</th>
      <td>6.5</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>148</th>
      <td>6.2</td>
      <td>3.4</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>149</th>
      <td>5.9</td>
      <td>3.0</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>Iris-virginica</td>
    </tr>
  </tbody>
</table>
</div>

<p><span id="MathJax-Element-24-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sepal length&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sepal width&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;petal length&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;petal width&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sepal length&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sepal width&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;petal length&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;petal width&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;150&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sepal length&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;150&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sepal width&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;150&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;petal length&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mn&gt;150&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;petal width&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;setosa&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;setosa&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;virginica&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-238"><span><span><span id="MathJax-Span-239"><span id="MathJax-Span-240"><span id="MathJax-Span-241"><span id="MathJax-Span-242"><span><span><span id="MathJax-Span-243"><span id="MathJax-Span-244">X<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-245"></span><span id="MathJax-Span-246"><span id="MathJax-Span-247"><span id="MathJax-Span-248">X<span></span></span></span></span><span id="MathJax-Span-249">=</span><span id="MathJax-Span-250"><span id="MathJax-Span-251"><span><span>⎡<span></span></span><span>⎣<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span></span></span><span id="MathJax-Span-252"><span><span><span><span><span id="MathJax-Span-253"><span id="MathJax-Span-254"><span id="MathJax-Span-255"><span><span><span id="MathJax-Span-256">x</span><span></span></span><span><span id="MathJax-Span-257"><span id="MathJax-Span-258"><span id="MathJax-Span-259"><span><span><span id="MathJax-Span-260">1</span><span></span></span><span><span id="MathJax-Span-261"><span id="MathJax-Span-262"><span id="MathJax-Span-263">sepal length</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-297"><span id="MathJax-Span-298"><span id="MathJax-Span-299"><span><span><span id="MathJax-Span-300">x</span><span></span></span><span><span id="MathJax-Span-301"><span id="MathJax-Span-302"><span id="MathJax-Span-303"><span><span><span id="MathJax-Span-304">2</span><span></span></span><span><span id="MathJax-Span-305"><span id="MathJax-Span-306"><span id="MathJax-Span-307">sepal length</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-341"><span id="MathJax-Span-342"><span id="MathJax-Span-343">.</span><span id="MathJax-Span-344">.</span><span id="MathJax-Span-345">.</span></span></span><span></span></span><span><span id="MathJax-Span-346"><span id="MathJax-Span-347"><span id="MathJax-Span-348"><span><span><span id="MathJax-Span-349">x</span><span></span></span><span><span id="MathJax-Span-350"><span id="MathJax-Span-351"><span id="MathJax-Span-352"><span><span><span id="MathJax-Span-353">150</span><span></span></span><span><span id="MathJax-Span-354"><span id="MathJax-Span-355"><span id="MathJax-Span-356">sepal length</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span></span><span></span></span><span><span><span><span id="MathJax-Span-264"><span id="MathJax-Span-265"><span id="MathJax-Span-266"><span><span><span id="MathJax-Span-267">x</span><span></span></span><span><span id="MathJax-Span-268"><span id="MathJax-Span-269"><span id="MathJax-Span-270"><span><span><span id="MathJax-Span-271">1</span><span></span></span><span><span id="MathJax-Span-272"><span id="MathJax-Span-273"><span id="MathJax-Span-274">sepal width</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-308"><span id="MathJax-Span-309"><span id="MathJax-Span-310"><span><span><span id="MathJax-Span-311">x</span><span></span></span><span><span id="MathJax-Span-312"><span id="MathJax-Span-313"><span id="MathJax-Span-314"><span><span><span id="MathJax-Span-315">2</span><span></span></span><span><span id="MathJax-Span-316"><span id="MathJax-Span-317"><span id="MathJax-Span-318">sepal width</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-357"><span id="MathJax-Span-358"><span id="MathJax-Span-359"><span><span><span id="MathJax-Span-360">x</span><span></span></span><span><span id="MathJax-Span-361"><span id="MathJax-Span-362"><span id="MathJax-Span-363"><span><span><span id="MathJax-Span-364">150</span><span></span></span><span><span id="MathJax-Span-365"><span id="MathJax-Span-366"><span id="MathJax-Span-367">sepal width</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span></span><span></span></span><span><span><span><span id="MathJax-Span-275"><span id="MathJax-Span-276"><span id="MathJax-Span-277"><span><span><span id="MathJax-Span-278">x</span><span></span></span><span><span id="MathJax-Span-279"><span id="MathJax-Span-280"><span id="MathJax-Span-281"><span><span><span id="MathJax-Span-282">1</span><span></span></span><span><span id="MathJax-Span-283"><span id="MathJax-Span-284"><span id="MathJax-Span-285">petal length</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-319"><span id="MathJax-Span-320"><span id="MathJax-Span-321"><span><span><span id="MathJax-Span-322">x</span><span></span></span><span><span id="MathJax-Span-323"><span id="MathJax-Span-324"><span id="MathJax-Span-325"><span><span><span id="MathJax-Span-326">2</span><span></span></span><span><span id="MathJax-Span-327"><span id="MathJax-Span-328"><span id="MathJax-Span-329">petal length</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-368"><span id="MathJax-Span-369"><span id="MathJax-Span-370"><span><span><span id="MathJax-Span-371">x</span><span></span></span><span><span id="MathJax-Span-372"><span id="MathJax-Span-373"><span id="MathJax-Span-374"><span><span><span id="MathJax-Span-375">150</span><span></span></span><span><span id="MathJax-Span-376"><span id="MathJax-Span-377"><span id="MathJax-Span-378">petal length</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span></span><span></span></span><span><span><span><span id="MathJax-Span-286"><span id="MathJax-Span-287"><span id="MathJax-Span-288"><span><span><span id="MathJax-Span-289">x</span><span></span></span><span><span id="MathJax-Span-290"><span id="MathJax-Span-291"><span id="MathJax-Span-292"><span><span><span id="MathJax-Span-293">1</span><span></span></span><span><span id="MathJax-Span-294"><span id="MathJax-Span-295"><span id="MathJax-Span-296">petal width</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-330"><span id="MathJax-Span-331"><span id="MathJax-Span-332"><span><span><span id="MathJax-Span-333">x</span><span></span></span><span><span id="MathJax-Span-334"><span id="MathJax-Span-335"><span id="MathJax-Span-336"><span><span><span id="MathJax-Span-337">2</span><span></span></span><span><span id="MathJax-Span-338"><span id="MathJax-Span-339"><span id="MathJax-Span-340">petal width</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-379"><span id="MathJax-Span-380"><span id="MathJax-Span-381"><span><span><span id="MathJax-Span-382">x</span><span></span></span><span><span id="MathJax-Span-383"><span id="MathJax-Span-384"><span id="MathJax-Span-385"><span><span><span id="MathJax-Span-386">150</span><span></span></span><span><span id="MathJax-Span-387"><span id="MathJax-Span-388"><span id="MathJax-Span-389">petal width</span></span></span><span></span></span></span></span></span></span><span></span></span></span></span></span></span><span></span></span></span><span></span></span></span></span><span id="MathJax-Span-390"><span><span>⎤<span></span></span><span>⎦<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span></span></span></span><span id="MathJax-Span-391">,</span><span id="MathJax-Span-392"></span><span id="MathJax-Span-393"></span><span id="MathJax-Span-394"><span id="MathJax-Span-395"><span id="MathJax-Span-396"><span><span><span id="MathJax-Span-397"><span id="MathJax-Span-398">y<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-399"></span><span id="MathJax-Span-400"><span id="MathJax-Span-401"><span id="MathJax-Span-402">y<span></span></span></span></span><span id="MathJax-Span-403">=</span><span id="MathJax-Span-404"><span id="MathJax-Span-405"><span><span>⎡<span></span></span><span>⎣<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span></span></span><span id="MathJax-Span-406"><span><span><span><span><span id="MathJax-Span-407"><span id="MathJax-Span-408"><span id="MathJax-Span-409"><span><span><span id="MathJax-Span-410">ω</span><span></span></span><span><span id="MathJax-Span-411"><span id="MathJax-Span-412"><span id="MathJax-Span-413">setosa</span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-414"><span id="MathJax-Span-415"><span id="MathJax-Span-416"><span><span><span id="MathJax-Span-417">ω</span><span></span></span><span><span id="MathJax-Span-418"><span id="MathJax-Span-419"><span id="MathJax-Span-420">setosa</span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-421"><span id="MathJax-Span-422"><span id="MathJax-Span-423">.</span><span id="MathJax-Span-424">.</span><span id="MathJax-Span-425">.</span></span></span><span></span></span><span><span id="MathJax-Span-426"><span id="MathJax-Span-427"><span id="MathJax-Span-428"><span><span><span id="MathJax-Span-429">ω</span><span></span></span><span><span id="MathJax-Span-430"><span id="MathJax-Span-431"><span id="MathJax-Span-432">virginica</span></span></span><span></span></span></span></span></span></span><span></span></span></span><span></span></span></span></span><span id="MathJax-Span-433"><span><span>⎤<span></span></span><span>⎦<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mpadded width="0"><mi>X</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>X</mi></mrow><mo>=</mo><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><msub><mi>x</mi><mrow><msub><mn>1</mn><mrow><mtext>sepal length</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>1</mn><mrow><mtext>sepal width</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>1</mn><mrow><mtext>petal length</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>1</mn><mrow><mtext>petal width</mtext></mrow></msub></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>x</mi><mrow><msub><mn>2</mn><mrow><mtext>sepal length</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>2</mn><mrow><mtext>sepal width</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>2</mn><mrow><mtext>petal length</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>2</mn><mrow><mtext>petal width</mtext></mrow></msub></mrow></msub></mtd></mtr><mtr><mtd><mo>.</mo><mo>.</mo><mo>.</mo></mtd></mtr><mtr><mtd><msub><mi>x</mi><mrow><msub><mn>150</mn><mrow><mtext>sepal length</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>150</mn><mrow><mtext>sepal width</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>150</mn><mrow><mtext>petal length</mtext></mrow></msub></mrow></msub></mtd><mtd><msub><mi>x</mi><mrow><msub><mn>150</mn><mrow><mtext>petal width</mtext></mrow></msub></mrow></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>,</mo><mspace width="thickmathspace"></mspace><mspace width="thickmathspace"></mspace><mrow><mpadded width="0"><mi>y</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>y</mi></mrow><mo>=</mo><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><msub><mi>ω</mi><mrow><mtext>setosa</mtext></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>ω</mi><mrow><mtext>setosa</mtext></mrow></msub></mtd></mtr><mtr><mtd><mo>.</mo><mo>.</mo><mo>.</mo></mtd></mtr><mtr><mtd><msub><mi>ω</mi><mrow><mtext>virginica</mtext></mrow></msub></mtd></mtr></mtable><mo>]</mo></mrow></math></span></span></p>



<p>Since it is more convenient to work with numerical values, we will use the <code>LabelEncode</code> from the <code>scikit-learn</code> library to convert the class labels into numbers: <code>1, 2, and 3</code>.</p>

<div><div><pre><code><span>from</span> <span>sklearn.preprocessing</span> <span>import</span> <span>LabelEncoder</span>

<span>X</span> <span>=</span> <span>df</span><span>[[</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]]</span><span>.</span><span>values</span>
<span>y</span> <span>=</span> <span>df</span><span>[</span><span>'class label'</span><span>]</span><span>.</span><span>values</span>

<span>enc</span> <span>=</span> <span>LabelEncoder</span><span>()</span>
<span>label_encoder</span> <span>=</span> <span>enc</span><span>.</span><span>fit</span><span>(</span><span>y</span><span>)</span>
<span>y</span> <span>=</span> <span>label_encoder</span><span>.</span><span>transform</span><span>(</span><span>y</span><span>)</span> <span>+</span> <span>1</span>

<span>label_dict</span> <span>=</span> <span>{</span><span>1</span><span>:</span> <span>'Setosa'</span><span>,</span> <span>2</span><span>:</span> <span>'Versicolor'</span><span>,</span> <span>3</span><span>:</span><span>'Virginica'</span><span>}</span>
</code></pre></div></div>

<p><span id="MathJax-Element-25-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;setosa&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;setosa&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;virginica&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1em&quot; /&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x21D2;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;1&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;1&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;3&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-434"><span><span><span id="MathJax-Span-435"><span id="MathJax-Span-436"><span id="MathJax-Span-437"><span id="MathJax-Span-438"><span><span><span id="MathJax-Span-439"><span id="MathJax-Span-440">y<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-441"></span><span id="MathJax-Span-442"><span id="MathJax-Span-443"><span id="MathJax-Span-444">y<span></span></span></span></span><span id="MathJax-Span-445">=</span><span id="MathJax-Span-446"><span id="MathJax-Span-447"><span><span>⎡<span></span></span><span>⎣<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span></span></span><span id="MathJax-Span-448"><span><span><span><span><span id="MathJax-Span-449"><span id="MathJax-Span-450"><span id="MathJax-Span-451"><span id="MathJax-Span-452"><span id="MathJax-Span-453">setosa</span></span></span></span></span><span></span></span><span><span id="MathJax-Span-454"><span id="MathJax-Span-455"><span id="MathJax-Span-456"><span id="MathJax-Span-457"><span id="MathJax-Span-458">setosa</span></span></span></span></span><span></span></span><span><span id="MathJax-Span-459"><span id="MathJax-Span-460"><span id="MathJax-Span-461">.</span><span id="MathJax-Span-462">.</span><span id="MathJax-Span-463">.</span></span></span><span></span></span><span><span id="MathJax-Span-464"><span id="MathJax-Span-465"><span id="MathJax-Span-466"><span id="MathJax-Span-467"><span id="MathJax-Span-468">virginica</span></span></span></span></span><span></span></span></span><span></span></span></span></span><span id="MathJax-Span-469"><span><span>⎤<span></span></span><span>⎦<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span></span></span></span><span id="MathJax-Span-470"></span><span id="MathJax-Span-471">⇒</span><span id="MathJax-Span-472"><span id="MathJax-Span-473"><span><span>⎡<span></span></span><span>⎣<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span></span></span><span id="MathJax-Span-474"><span><span><span><span><span id="MathJax-Span-475"><span id="MathJax-Span-476"><span id="MathJax-Span-477"><span id="MathJax-Span-478"><span id="MathJax-Span-479">1</span></span></span></span></span><span></span></span><span><span id="MathJax-Span-480"><span id="MathJax-Span-481"><span id="MathJax-Span-482"><span id="MathJax-Span-483"><span id="MathJax-Span-484">1</span></span></span></span></span><span></span></span><span><span id="MathJax-Span-485"><span id="MathJax-Span-486"><span id="MathJax-Span-487">.</span><span id="MathJax-Span-488">.</span><span id="MathJax-Span-489">.</span></span></span><span></span></span><span><span id="MathJax-Span-490"><span id="MathJax-Span-491"><span id="MathJax-Span-492"><span id="MathJax-Span-493"><span id="MathJax-Span-494">3</span></span></span></span></span><span></span></span></span><span></span></span></span></span><span id="MathJax-Span-495"><span><span>⎤<span></span></span><span>⎦<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mpadded width="0"><mi>y</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>y</mi></mrow><mo>=</mo><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mrow><mtext>setosa</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>setosa</mtext></mrow></mtd></mtr><mtr><mtd><mo>.</mo><mo>.</mo><mo>.</mo></mtd></mtr><mtr><mtd><mrow><mtext>virginica</mtext></mrow></mtd></mtr></mtable><mo>]</mo></mrow><mspace width="1em"></mspace><mo stretchy="false">⇒</mo><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mrow><mtext>1</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>1</mtext></mrow></mtd></mtr><mtr><mtd><mo>.</mo><mo>.</mo><mo>.</mo></mtd></mtr><mtr><mtd><mrow><mtext>3</mtext></mrow></mtd></mtr></mtable><mo>]</mo></mrow></math></span></span></p>



<h3 id="histograms-and-feature-selection">Histograms and feature selection<a href="#histograms-and-feature-selection" aria-label="Anchor link for: histograms and feature selection" data-anchorjs-icon=""></a></h3>

<p>Just to get a rough idea how the samples of our three classes <span id="MathJax-Element-26-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-496"><span><span><span id="MathJax-Span-497"><span id="MathJax-Span-498"><span><span><span id="MathJax-Span-499">ω</span><span></span></span><span><span id="MathJax-Span-500">1</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ω</mi><mn>1</mn></msub></math></span></span>, <span id="MathJax-Element-27-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-501"><span><span><span id="MathJax-Span-502"><span id="MathJax-Span-503"><span><span><span id="MathJax-Span-504">ω</span><span></span></span><span><span id="MathJax-Span-505">2</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ω</mi><mn>2</mn></msub></math></span></span> and <span id="MathJax-Element-28-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-506"><span><span><span id="MathJax-Span-507"><span id="MathJax-Span-508"><span><span><span id="MathJax-Span-509">ω</span><span></span></span><span><span id="MathJax-Span-510">3</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ω</mi><mn>3</mn></msub></math></span></span> are distributed, let us visualize the distributions of the four different features in 1-dimensional histograms.</p>



<div><div><pre><code><span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>math</span>

<span>fig</span><span>,</span> <span>axes</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>nrows</span><span>=</span><span>2</span><span>,</span> <span>ncols</span><span>=</span><span>2</span><span>,</span> <span>figsize</span><span>=</span><span>(</span><span>12</span><span>,</span><span>6</span><span>))</span>

<span>for</span> <span>ax</span><span>,</span><span>cnt</span> <span>in</span> <span>zip</span><span>(</span><span>axes</span><span>.</span><span>ravel</span><span>(),</span> <span>range</span><span>(</span><span>4</span><span>)):</span>  

    <span># set bin sizes</span>
    <span>min_b</span> <span>=</span> <span>math</span><span>.</span><span>floor</span><span>(</span><span>np</span><span>.</span><span>min</span><span>(</span><span>X</span><span>[:,</span><span>cnt</span><span>]))</span>
    <span>max_b</span> <span>=</span> <span>math</span><span>.</span><span>ceil</span><span>(</span><span>np</span><span>.</span><span>max</span><span>(</span><span>X</span><span>[:,</span><span>cnt</span><span>]))</span>
    <span>bins</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>min_b</span><span>,</span> <span>max_b</span><span>,</span> <span>25</span><span>)</span>

    <span># plottling the histograms</span>
    <span>for</span> <span>lab</span><span>,</span><span>col</span> <span>in</span> <span>zip</span><span>(</span><span>range</span><span>(</span><span>1</span><span>,</span><span>4</span><span>),</span> <span>(</span><span>'blue'</span><span>,</span> <span>'red'</span><span>,</span> <span>'green'</span><span>)):</span>
        <span>ax</span><span>.</span><span>hist</span><span>(</span><span>X</span><span>[</span><span>y</span><span>==</span><span>lab</span><span>,</span> <span>cnt</span><span>],</span>
                   <span>color</span><span>=</span><span>col</span><span>,</span>
                   <span>label</span><span>=</span><span>'class </span><span>%</span><span>s'</span> <span>%</span><span>label_dict</span><span>[</span><span>lab</span><span>],</span>
                   <span>bins</span><span>=</span><span>bins</span><span>,</span>
                   <span>alpha</span><span>=</span><span>0.5</span><span>,)</span>
    <span>ylims</span> <span>=</span> <span>ax</span><span>.</span><span>get_ylim</span><span>()</span>

    <span># plot annotation</span>
    <span>leg</span> <span>=</span> <span>ax</span><span>.</span><span>legend</span><span>(</span><span>loc</span><span>=</span><span>'upper right'</span><span>,</span> <span>fancybox</span><span>=</span><span>True</span><span>,</span> <span>fontsize</span><span>=</span><span>8</span><span>)</span>
    <span>leg</span><span>.</span><span>get_frame</span><span>()</span><span>.</span><span>set_alpha</span><span>(</span><span>0.5</span><span>)</span>
    <span>ax</span><span>.</span><span>set_ylim</span><span>([</span><span>0</span><span>,</span> <span>max</span><span>(</span><span>ylims</span><span>)</span><span>+</span><span>2</span><span>])</span>
    <span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span>feature_dict</span><span>[</span><span>cnt</span><span>])</span>
    <span>ax</span><span>.</span><span>set_title</span><span>(</span><span>'Iris histogram #</span><span>%</span><span>s'</span> <span>%</span><span>str</span><span>(</span><span>cnt</span><span>+</span><span>1</span><span>))</span>

    <span># hide axis ticks</span>
    <span>ax</span><span>.</span><span>tick_params</span><span>(</span><span>axis</span><span>=</span><span>"both"</span><span>,</span> <span>which</span><span>=</span><span>"both"</span><span>,</span> <span>bottom</span><span>=</span><span>"off"</span><span>,</span> <span>top</span><span>=</span><span>"off"</span><span>,</span>  
            <span>labelbottom</span><span>=</span><span>"on"</span><span>,</span> <span>left</span><span>=</span><span>"off"</span><span>,</span> <span>right</span><span>=</span><span>"off"</span><span>,</span> <span>labelleft</span><span>=</span><span>"on"</span><span>)</span>

    <span># remove axis spines</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"top"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>  
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"right"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"bottom"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"left"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>    

<span>axes</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span><span>.</span><span>set_ylabel</span><span>(</span><span>'count'</span><span>)</span>
<span>axes</span><span>[</span><span>1</span><span>][</span><span>0</span><span>]</span><span>.</span><span>set_ylabel</span><span>(</span><span>'count'</span><span>)</span>

<span>fig</span><span>.</span><span>tight_layout</span><span>()</span>       

<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_51_0.png" alt="png" moz-reader-center="true"></p>

<p>From just looking at these simple graphical representations of the 
features, we can already tell that the petal lengths and widths are 
likely better suited as potential features two separate between the 
three flower classes. In practice, instead of reducing the 
dimensionality via a projection (here: LDA), a good alternative would be
 a feature selection technique. For low-dimensional datasets like Iris, a
 glance at those histograms would already be very informative. Another 
simple, but very useful technique would be to use feature selection 
algorithms; in case you are interested, I have a more detailed 
description on sequential feature selection algorithms <a href="http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/">here</a>, and scikit-learn also implements a nice selection of alternative <a href="http://scikit-learn.org/stable/modules/feature_selection.html">approaches</a>. For a high-level summary of the different approaches, I’ve written a short post on <a href="https://sebastianraschka.com/faq/docs/feature_sele_categories.html">“What is the difference between filter, wrapper, and embedded methods for feature selection?”</a>.</p>



<h3 id="normality-assumptions">Normality assumptions<a href="#normality-assumptions" aria-label="Anchor link for: normality assumptions" data-anchorjs-icon=""></a></h3>

<p>It should be mentioned that LDA assumes normal distributed data, 
features that are statistically independent, and identical covariance 
matrices for every class. However, this only applies for LDA as 
classifier and LDA for dimensionality reduction can also work reasonably
 well if those assumptions are violated. And even for classification 
tasks LDA seems can be quite robust to the distribution of the data:</p>

<blockquote>
  <p>“linear discriminant analysis frequently achieves good performances in
the tasks of face and object recognition, even though the assumptions
of common covariance matrix among groups and normality are often
violated (Duda, et al., 2001)” (Tao Li, et al., 2006).</p>
</blockquote>

<p>Tao Li, Shenghuo Zhu, and Mitsunori Ogihara. “<a href="http://link.springer.com/article/10.1007%2Fs10115-006-0013-y">Using Discriminant Analysis for Multi-Class Classification: An Experimental Investigation</a>.” Knowledge and Information Systems 10, no. 4 (2006): 453–72.)</p>

<p>Duda, Richard O, Peter E Hart, and David G Stork. 2001. Pattern Classification. New York: Wiley.</p>



<h2 id="lda-in-5-steps">LDA in 5 steps<a href="#lda-in-5-steps" aria-label="Anchor link for: lda in 5 steps" data-anchorjs-icon=""></a></h2>

<p>After we went through several preparation steps, our data is finally 
ready for the actual LDA. In practice, LDA for dimensionality reduction 
would be just another preprocessing step for a typical machine learning 
or pattern classification task.</p>



<h3 id="step-1-computing-the-d-dimensional-mean-vectors">Step 1: Computing the d-dimensional mean vectors<a href="#step-1-computing-the-d-dimensional-mean-vectors" aria-label="Anchor link for: step 1 computing the d dimensional mean vectors" data-anchorjs-icon=""></a></h3>

<p>In this first step, we will start off with a simple computation of the mean vectors <span id="MathJax-Element-29-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-511"><span><span><span id="MathJax-Span-512"><span id="MathJax-Span-513"><span id="MathJax-Span-514"><span id="MathJax-Span-515"><span><span><span id="MathJax-Span-516"><span id="MathJax-Span-517">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-518"></span><span id="MathJax-Span-519"><span><span><span id="MathJax-Span-520"><span id="MathJax-Span-521"><span id="MathJax-Span-522">m</span></span></span><span></span></span><span><span id="MathJax-Span-523">i</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub></math></span></span>, <span id="MathJax-Element-30-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-524"><span><span><span id="MathJax-Span-525"><span id="MathJax-Span-526">(</span><span id="MathJax-Span-527">i</span><span id="MathJax-Span-528">=</span><span id="MathJax-Span-529">1</span><span id="MathJax-Span-530">,</span><span id="MathJax-Span-531">2</span><span id="MathJax-Span-532">,</span><span id="MathJax-Span-533">3</span><span id="MathJax-Span-534">)</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo stretchy="false">)</mo></math></span></span> of the 3 different flower classes:</p>

<p><span id="MathJax-Element-31-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03BC;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;sepal length)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03BC;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;sepal width&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03BC;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;petal length)&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03BC;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C9;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;petal width&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;1em&quot; /&gt;&lt;mtext&gt;with&lt;/mtext&gt;&lt;mspace width=&quot;1em&quot; /&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-535"><span><span><span id="MathJax-Span-536"><span id="MathJax-Span-537"><span id="MathJax-Span-538"><span id="MathJax-Span-539"><span><span><span id="MathJax-Span-540"><span id="MathJax-Span-541">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-542"></span><span id="MathJax-Span-543"><span><span><span id="MathJax-Span-544"><span id="MathJax-Span-545"><span id="MathJax-Span-546">m</span></span></span><span></span></span><span><span id="MathJax-Span-547">i</span><span></span></span></span></span><span id="MathJax-Span-548">=</span><span id="MathJax-Span-549"><span id="MathJax-Span-550"><span><span>⎡<span></span></span><span>⎣<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span><span>⎢<span></span></span></span></span><span id="MathJax-Span-551"><span><span><span><span><span id="MathJax-Span-552"><span id="MathJax-Span-553"><span id="MathJax-Span-554"><span><span><span id="MathJax-Span-555">μ</span><span></span></span><span><span id="MathJax-Span-556"><span id="MathJax-Span-557"><span id="MathJax-Span-558"><span><span><span id="MathJax-Span-559">ω</span><span></span></span><span><span id="MathJax-Span-560">i</span><span></span></span></span></span><span id="MathJax-Span-561">(</span><span id="MathJax-Span-562">sepal length)</span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-563"><span id="MathJax-Span-564"><span id="MathJax-Span-565"><span><span><span id="MathJax-Span-566">μ</span><span></span></span><span><span id="MathJax-Span-567"><span id="MathJax-Span-568"><span id="MathJax-Span-569"><span><span><span id="MathJax-Span-570">ω</span><span></span></span><span><span id="MathJax-Span-571">i</span><span></span></span></span></span><span id="MathJax-Span-572">(</span><span id="MathJax-Span-573">sepal width</span><span id="MathJax-Span-574">)</span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-575"><span id="MathJax-Span-576"><span id="MathJax-Span-577"><span><span><span id="MathJax-Span-578">μ</span><span></span></span><span><span id="MathJax-Span-579"><span id="MathJax-Span-580"><span id="MathJax-Span-581"><span><span><span id="MathJax-Span-582">ω</span><span></span></span><span><span id="MathJax-Span-583">i</span><span></span></span></span></span><span id="MathJax-Span-584">(</span><span id="MathJax-Span-585">petal length)</span></span></span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-586"><span id="MathJax-Span-587"><span id="MathJax-Span-588"><span><span><span id="MathJax-Span-589">μ</span><span></span></span><span><span id="MathJax-Span-590"><span id="MathJax-Span-591"><span id="MathJax-Span-592"><span><span><span id="MathJax-Span-593">ω</span><span></span></span><span><span id="MathJax-Span-594">i</span><span></span></span></span></span><span id="MathJax-Span-595">(</span><span id="MathJax-Span-596">petal width</span><span id="MathJax-Span-597">)</span></span></span><span></span></span></span></span></span></span><span></span></span></span><span></span></span></span></span><span id="MathJax-Span-598"><span><span>⎤<span></span></span><span>⎦<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span><span>⎥<span></span></span></span></span></span><span id="MathJax-Span-599"></span><span id="MathJax-Span-600">,</span><span id="MathJax-Span-601"></span><span id="MathJax-Span-602">with</span><span id="MathJax-Span-603"></span><span id="MathJax-Span-604">i</span><span id="MathJax-Span-605">=</span><span id="MathJax-Span-606">1</span><span id="MathJax-Span-607">,</span><span id="MathJax-Span-608">2</span><span id="MathJax-Span-609">,</span><span id="MathJax-Span-610">3</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><msub><mi>μ</mi><mrow><msub><mi>ω</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mtext>sepal length)</mtext></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>μ</mi><mrow><msub><mi>ω</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mtext>sepal width</mtext><mo stretchy="false">)</mo></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>μ</mi><mrow><msub><mi>ω</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mtext>petal length)</mtext></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>μ</mi><mrow><msub><mi>ω</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mtext>petal width</mtext><mo stretchy="false">)</mo></mrow></msub></mtd></mtr></mtable><mo>]</mo></mrow><mspace width="thickmathspace"></mspace><mo>,</mo><mspace width="1em"></mspace><mtext>with</mtext><mspace width="1em"></mspace><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn></math></span></span></p>

<div><div><pre><code><span>np</span><span>.</span><span>set_printoptions</span><span>(</span><span>precision</span><span>=</span><span>4</span><span>)</span>

<span>mean_vectors</span> <span>=</span> <span>[]</span>
<span>for</span> <span>cl</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span><span>4</span><span>):</span>
    <span>mean_vectors</span><span>.</span><span>append</span><span>(</span><span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>[</span><span>y</span><span>==</span><span>cl</span><span>],</span> <span>axis</span><span>=</span><span>0</span><span>))</span>
    <span>print</span><span>(</span><span>'Mean Vector class </span><span>%</span><span>s: </span><span>%</span><span>s</span><span>\n</span><span>'</span> <span>%</span><span>(</span><span>cl</span><span>,</span> <span>mean_vectors</span><span>[</span><span>cl</span><span>-</span><span>1</span><span>]))</span>
</code></pre></div></div>

<div><div><pre><code>Mean Vector class 1: [ 5.006  3.418  1.464  0.244]

Mean Vector class 2: [ 5.936  2.77   4.26   1.326]

Mean Vector class 3: [ 6.588  2.974  5.552  2.026]
</code></pre></div></div>





<h3 id="step-2-computing-the-scatter-matrices">Step 2: Computing the Scatter Matrices<a href="#step-2-computing-the-scatter-matrices" aria-label="Anchor link for: step 2 computing the scatter matrices" data-anchorjs-icon=""></a></h3>

<p>Now, we will compute the two <em>4x4</em>-dimensional matrices: The within-class and the between-class scatter matrix.</p>

<h4 id="21-within-class-scatter-matrix-s_w">2.1 Within-class scatter matrix <span id="MathJax-Element-32-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-611"><span><span><span id="MathJax-Span-612"><span id="MathJax-Span-613"><span><span><span id="MathJax-Span-614">S<span></span></span><span></span></span><span><span id="MathJax-Span-615">W<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>W</mi></msub></math></span></span><a href="#21-within-class-scatter-matrix-s_w" aria-label="Anchor link for: 21 within class scatter matrix s_w" data-anchorjs-icon=""></a></h4>

<p>The <strong>within-class scatter</strong> matrix <span id="MathJax-Element-33-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-616"><span><span><span id="MathJax-Span-617"><span id="MathJax-Span-618"><span><span><span id="MathJax-Span-619">S<span></span></span><span></span></span><span><span id="MathJax-Span-620">W<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>W</mi></msub></math></span></span> is computed by the following equation:</p>

<p><span id="MathJax-Element-34-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo movablelimits=&quot;false&quot;&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-621"><span><span><span id="MathJax-Span-622"><span id="MathJax-Span-623"><span><span><span id="MathJax-Span-624">S<span></span></span><span></span></span><span><span id="MathJax-Span-625">W<span></span></span><span></span></span></span></span><span id="MathJax-Span-626">=</span><span id="MathJax-Span-627"><span><span><span id="MathJax-Span-628">∑</span><span></span></span><span><span id="MathJax-Span-629"><span id="MathJax-Span-630"><span id="MathJax-Span-631">i</span><span id="MathJax-Span-632">=</span><span id="MathJax-Span-633">1</span></span></span><span></span></span><span><span id="MathJax-Span-634"><span id="MathJax-Span-635"><span id="MathJax-Span-636">c</span></span></span><span></span></span></span></span><span id="MathJax-Span-637"><span><span><span id="MathJax-Span-638">S<span></span></span><span></span></span><span><span id="MathJax-Span-639">i</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>S</mi><mi>W</mi></msub><mo>=</mo><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>c</mi></mrow></munderover><msub><mi>S</mi><mi>i</mi></msub></math></span></span></p>

<p>where<br>
<span id="MathJax-Element-35-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo movablelimits=&quot;false&quot;&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-640"><span><span><span id="MathJax-Span-641"><span id="MathJax-Span-642"><span><span><span id="MathJax-Span-643">S<span></span></span><span></span></span><span><span id="MathJax-Span-644">i</span><span></span></span></span></span><span id="MathJax-Span-645">=</span><span id="MathJax-Span-646"><span><span><span id="MathJax-Span-647">∑</span><span></span></span><span><span id="MathJax-Span-648"><span id="MathJax-Span-649"><span id="MathJax-Span-650"><span id="MathJax-Span-651"><span id="MathJax-Span-652"><span><span><span id="MathJax-Span-653"><span id="MathJax-Span-654">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-655"></span><span id="MathJax-Span-656"><span id="MathJax-Span-657"><span id="MathJax-Span-658">x</span></span></span><span id="MathJax-Span-659">∈</span><span id="MathJax-Span-660"><span><span><span id="MathJax-Span-661">D</span><span></span></span><span><span id="MathJax-Span-662">i</span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-663">n</span><span></span></span></span></span><span id="MathJax-Span-664">(</span><span id="MathJax-Span-665"><span id="MathJax-Span-666"><span id="MathJax-Span-667"><span><span><span id="MathJax-Span-668"><span id="MathJax-Span-669">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-670"></span><span id="MathJax-Span-671"><span id="MathJax-Span-672"><span id="MathJax-Span-673">x</span></span></span><span id="MathJax-Span-674">−</span><span id="MathJax-Span-675"><span id="MathJax-Span-676"><span id="MathJax-Span-677"><span><span><span id="MathJax-Span-678"><span id="MathJax-Span-679">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-680"></span><span id="MathJax-Span-681"><span><span><span id="MathJax-Span-682"><span id="MathJax-Span-683"><span id="MathJax-Span-684">m</span></span></span><span></span></span><span><span id="MathJax-Span-685">i</span><span></span></span></span></span><span id="MathJax-Span-686">)</span><span id="MathJax-Span-687"></span><span id="MathJax-Span-688">(</span><span id="MathJax-Span-689"><span id="MathJax-Span-690"><span id="MathJax-Span-691"><span><span><span id="MathJax-Span-692"><span id="MathJax-Span-693">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-694"></span><span id="MathJax-Span-695"><span id="MathJax-Span-696"><span id="MathJax-Span-697">x</span></span></span><span id="MathJax-Span-698">−</span><span id="MathJax-Span-699"><span id="MathJax-Span-700"><span id="MathJax-Span-701"><span><span><span id="MathJax-Span-702"><span id="MathJax-Span-703">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-704"></span><span id="MathJax-Span-705"><span><span><span id="MathJax-Span-706"><span id="MathJax-Span-707"><span id="MathJax-Span-708">m</span></span></span><span></span></span><span><span id="MathJax-Span-709">i</span><span></span></span></span></span><span id="MathJax-Span-710"><span><span><span id="MathJax-Span-711">)</span><span></span></span><span><span id="MathJax-Span-712">T<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><munderover><mo movablelimits="false">∑</mo><mrow><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>∈</mo><msub><mi>D</mi><mi>i</mi></msub></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>−</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mspace width="thickmathspace"></mspace><mo stretchy="false">(</mo><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>−</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup></math></span></span><br>
(scatter matrix for every class)</p>

<p>and <span id="MathJax-Element-36-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-713"><span><span><span id="MathJax-Span-714"><span id="MathJax-Span-715"><span id="MathJax-Span-716"><span id="MathJax-Span-717"><span><span><span id="MathJax-Span-718"><span id="MathJax-Span-719">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-720"></span><span id="MathJax-Span-721"><span><span><span id="MathJax-Span-722"><span id="MathJax-Span-723"><span id="MathJax-Span-724">m</span></span></span><span></span></span><span><span id="MathJax-Span-725">i</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub></math></span></span> is the mean vector  <br>
<span id="MathJax-Element-37-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfrac&gt;&lt;munderover&gt;&lt;mo movablelimits=&quot;false&quot;&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-726"><span><span><span id="MathJax-Span-727"><span id="MathJax-Span-728"><span id="MathJax-Span-729"><span id="MathJax-Span-730"><span><span><span id="MathJax-Span-731"><span id="MathJax-Span-732">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-733"></span><span id="MathJax-Span-734"><span><span><span id="MathJax-Span-735"><span id="MathJax-Span-736"><span id="MathJax-Span-737">m</span></span></span><span></span></span><span><span id="MathJax-Span-738">i</span><span></span></span></span></span><span id="MathJax-Span-739">=</span><span id="MathJax-Span-740"><span><span><span id="MathJax-Span-741">1</span><span></span></span><span><span id="MathJax-Span-742"><span><span><span id="MathJax-Span-743">n</span><span></span></span><span><span id="MathJax-Span-744">i</span><span></span></span></span></span><span></span></span><span><span></span><span></span></span></span></span><span id="MathJax-Span-745"><span><span><span id="MathJax-Span-746">∑</span><span></span></span><span><span id="MathJax-Span-747"><span id="MathJax-Span-748"><span id="MathJax-Span-749"><span id="MathJax-Span-750"><span id="MathJax-Span-751"><span><span><span id="MathJax-Span-752"><span id="MathJax-Span-753">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-754"></span><span id="MathJax-Span-755"><span id="MathJax-Span-756"><span id="MathJax-Span-757">x</span></span></span><span id="MathJax-Span-758">∈</span><span id="MathJax-Span-759"><span><span><span id="MathJax-Span-760">D</span><span></span></span><span><span id="MathJax-Span-761">i</span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-762">n</span><span></span></span></span></span><span id="MathJax-Span-763"></span><span id="MathJax-Span-764"><span id="MathJax-Span-765"><span id="MathJax-Span-766"><span><span><span id="MathJax-Span-767"><span id="MathJax-Span-768">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-769"></span><span id="MathJax-Span-770"><span><span><span id="MathJax-Span-771"><span id="MathJax-Span-772"><span id="MathJax-Span-773">x</span></span></span><span></span></span><span><span id="MathJax-Span-774">k</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><msub><mi>n</mi><mi>i</mi></msub></mfrac><munderover><mo movablelimits="false">∑</mo><mrow><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>∈</mo><msub><mi>D</mi><mi>i</mi></msub></mrow><mi>n</mi></munderover><mspace width="thickmathspace"></mspace><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>x</mi></mrow><mi>k</mi></msub></math></span></span></p>

<div><div><pre><code><span>S_W</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>4</span><span>,</span><span>4</span><span>))</span>
<span>for</span> <span>cl</span><span>,</span><span>mv</span> <span>in</span> <span>zip</span><span>(</span><span>range</span><span>(</span><span>1</span><span>,</span><span>4</span><span>),</span> <span>mean_vectors</span><span>):</span>
    <span>class_sc_mat</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>4</span><span>,</span><span>4</span><span>))</span>                  <span># scatter matrix for every class</span>
    <span>for</span> <span>row</span> <span>in</span> <span>X</span><span>[</span><span>y</span> <span>==</span> <span>cl</span><span>]:</span>
        <span>row</span><span>,</span> <span>mv</span> <span>=</span> <span>row</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>),</span> <span>mv</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>)</span> <span># make column vectors</span>
        <span>class_sc_mat</span> <span>+=</span> <span>(</span><span>row</span><span>-</span><span>mv</span><span>)</span><span>.</span><span>dot</span><span>((</span><span>row</span><span>-</span><span>mv</span><span>)</span><span>.</span><span>T</span><span>)</span>
    <span>S_W</span> <span>+=</span> <span>class_sc_mat</span>                             <span># sum class scatter matrices</span>
<span>print</span><span>(</span><span>'within-class Scatter Matrix:</span><span>\n</span><span>'</span><span>,</span> <span>S_W</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>within-class Scatter Matrix:
 [[ 38.9562  13.683   24.614    5.6556]
 [ 13.683   17.035    8.12     4.9132]
 [ 24.614    8.12    27.22     6.2536]
 [  5.6556   4.9132   6.2536   6.1756]]
</code></pre></div></div>

<h4 id="21-b">2.1 b<a href="#21-b" aria-label="Anchor link for: 21 b" data-anchorjs-icon=""></a></h4>

<p>Alternatively, we could also compute the class-covariance matrices by adding the scaling factor <span id="MathJax-Element-38-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-775"><span><span><span id="MathJax-Span-776"><span id="MathJax-Span-777"><span><span><span id="MathJax-Span-778">1</span><span></span></span><span><span id="MathJax-Span-779"><span id="MathJax-Span-780">N<span></span></span><span id="MathJax-Span-781">−</span><span id="MathJax-Span-782">1</span></span><span></span></span><span><span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac></math></span></span> to the within-class scatter matrix, so that our equation becomes</p>

<p><span id="MathJax-Element-39-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x03A3;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;munderover&gt;&lt;mo movablelimits=&quot;false&quot;&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-783"><span><span><span id="MathJax-Span-784"><span id="MathJax-Span-785"><span><span><span id="MathJax-Span-786">Σ</span><span></span></span><span><span id="MathJax-Span-787">i</span><span></span></span></span></span><span id="MathJax-Span-788">=</span><span id="MathJax-Span-789"><span><span><span id="MathJax-Span-790">1</span><span></span></span><span><span id="MathJax-Span-791"><span id="MathJax-Span-792"><span><span><span id="MathJax-Span-793">N<span></span></span><span></span></span><span><span id="MathJax-Span-794"><span id="MathJax-Span-795"><span id="MathJax-Span-796">i</span></span></span><span></span></span></span></span><span id="MathJax-Span-797">−</span><span id="MathJax-Span-798">1</span></span><span></span></span><span><span></span><span></span></span></span></span><span id="MathJax-Span-799"><span><span><span id="MathJax-Span-800">∑</span><span></span></span><span><span id="MathJax-Span-801"><span id="MathJax-Span-802"><span id="MathJax-Span-803"><span id="MathJax-Span-804"><span id="MathJax-Span-805"><span><span><span id="MathJax-Span-806"><span id="MathJax-Span-807">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-808"></span><span id="MathJax-Span-809"><span id="MathJax-Span-810"><span id="MathJax-Span-811">x</span></span></span><span id="MathJax-Span-812">∈</span><span id="MathJax-Span-813"><span><span><span id="MathJax-Span-814">D</span><span></span></span><span><span id="MathJax-Span-815">i</span><span></span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-816">n</span><span></span></span></span></span><span id="MathJax-Span-817">(</span><span id="MathJax-Span-818"><span id="MathJax-Span-819"><span id="MathJax-Span-820"><span><span><span id="MathJax-Span-821"><span id="MathJax-Span-822">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-823"></span><span id="MathJax-Span-824"><span id="MathJax-Span-825"><span id="MathJax-Span-826">x</span></span></span><span id="MathJax-Span-827">−</span><span id="MathJax-Span-828"><span id="MathJax-Span-829"><span id="MathJax-Span-830"><span><span><span id="MathJax-Span-831"><span id="MathJax-Span-832">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-833"></span><span id="MathJax-Span-834"><span><span><span id="MathJax-Span-835"><span id="MathJax-Span-836"><span id="MathJax-Span-837">m</span></span></span><span></span></span><span><span id="MathJax-Span-838">i</span><span></span></span></span></span><span id="MathJax-Span-839">)</span><span id="MathJax-Span-840"></span><span id="MathJax-Span-841">(</span><span id="MathJax-Span-842"><span id="MathJax-Span-843"><span id="MathJax-Span-844"><span><span><span id="MathJax-Span-845"><span id="MathJax-Span-846">x</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-847"></span><span id="MathJax-Span-848"><span id="MathJax-Span-849"><span id="MathJax-Span-850">x</span></span></span><span id="MathJax-Span-851">−</span><span id="MathJax-Span-852"><span id="MathJax-Span-853"><span id="MathJax-Span-854"><span><span><span id="MathJax-Span-855"><span id="MathJax-Span-856">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-857"></span><span id="MathJax-Span-858"><span><span><span id="MathJax-Span-859"><span id="MathJax-Span-860"><span id="MathJax-Span-861">m</span></span></span><span></span></span><span><span id="MathJax-Span-862">i</span><span></span></span></span></span><span id="MathJax-Span-863"><span><span><span id="MathJax-Span-864">)</span><span></span></span><span><span id="MathJax-Span-865">T<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="normal">Σ</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><msub><mi>N</mi><mrow><mi>i</mi></mrow></msub><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo movablelimits="false">∑</mo><mrow><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>∈</mo><msub><mi>D</mi><mi>i</mi></msub></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>−</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mspace width="thickmathspace"></mspace><mo stretchy="false">(</mo><mrow><mpadded width="0"><mi>x</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>x</mi></mrow><mo>−</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup></math></span></span>.</p>

<p>and <span id="MathJax-Element-40-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo movablelimits=&quot;false&quot;&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x03A3;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-866"><span><span><span id="MathJax-Span-867"><span id="MathJax-Span-868"><span><span><span id="MathJax-Span-869">S<span></span></span><span></span></span><span><span id="MathJax-Span-870">W<span></span></span><span></span></span></span></span><span id="MathJax-Span-871">=</span><span id="MathJax-Span-872"><span><span><span id="MathJax-Span-873">∑</span><span></span></span><span><span id="MathJax-Span-874"><span id="MathJax-Span-875"><span id="MathJax-Span-876">i</span><span id="MathJax-Span-877">=</span><span id="MathJax-Span-878">1</span></span></span><span></span></span><span><span id="MathJax-Span-879"><span id="MathJax-Span-880"><span id="MathJax-Span-881">c</span></span></span><span></span></span></span></span><span id="MathJax-Span-882">(</span><span id="MathJax-Span-883"><span><span><span id="MathJax-Span-884">N<span></span></span><span></span></span><span><span id="MathJax-Span-885"><span id="MathJax-Span-886"><span id="MathJax-Span-887">i</span></span></span><span></span></span></span></span><span id="MathJax-Span-888">−</span><span id="MathJax-Span-889">1</span><span id="MathJax-Span-890">)</span><span id="MathJax-Span-891"><span><span><span id="MathJax-Span-892">Σ</span><span></span></span><span><span id="MathJax-Span-893">i</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>W</mi></msub><mo>=</mo><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>c</mi></mrow></munderover><mo stretchy="false">(</mo><msub><mi>N</mi><mrow><mi>i</mi></mrow></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><msub><mi mathvariant="normal">Σ</mi><mi>i</mi></msub></math></span></span></p>

<p>where <span id="MathJax-Element-41-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-894"><span><span><span id="MathJax-Span-895"><span id="MathJax-Span-896"><span><span><span id="MathJax-Span-897">N<span></span></span><span></span></span><span><span id="MathJax-Span-898"><span id="MathJax-Span-899"><span id="MathJax-Span-900">i</span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mrow><mi>i</mi></mrow></msub></math></span></span> is the sample size of the respective class (here: 50), and in this particular case, we can drop the term (<span id="MathJax-Element-42-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-901"><span><span><span id="MathJax-Span-902"><span id="MathJax-Span-903"><span><span><span id="MathJax-Span-904">N<span></span></span><span></span></span><span><span id="MathJax-Span-905"><span id="MathJax-Span-906"><span id="MathJax-Span-907">i</span></span></span><span></span></span></span></span><span id="MathJax-Span-908">−</span><span id="MathJax-Span-909">1</span><span id="MathJax-Span-910">)</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mrow><mi>i</mi></mrow></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></math></span></span>
since all classes have the same sample size.</p>

<p>However, the resulting eigenspaces will be identical (identical 
eigenvectors, only the eigenvalues are scaled differently by a constant 
factor).</p>

<h4 id="22-between-class-scatter-matrix-s_b">2.2 Between-class scatter matrix <span id="MathJax-Element-43-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-911"><span><span><span id="MathJax-Span-912"><span id="MathJax-Span-913"><span><span><span id="MathJax-Span-914">S<span></span></span><span></span></span><span><span id="MathJax-Span-915">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>B</mi></msub></math></span></span><a href="#22-between-class-scatter-matrix-s_b" aria-label="Anchor link for: 22 between class scatter matrix s_b" data-anchorjs-icon=""></a></h4>

<p>The <strong>between-class scatter</strong> matrix <span id="MathJax-Element-44-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-916"><span><span><span id="MathJax-Span-917"><span id="MathJax-Span-918"><span><span><span id="MathJax-Span-919">S<span></span></span><span></span></span><span><span id="MathJax-Span-920">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>B</mi></msub></math></span></span> is computed by the following equation:</p>

<p><span id="MathJax-Element-45-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo movablelimits=&quot;false&quot;&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-921"><span><span><span id="MathJax-Span-922"><span id="MathJax-Span-923"><span><span><span id="MathJax-Span-924">S<span></span></span><span></span></span><span><span id="MathJax-Span-925">B</span><span></span></span></span></span><span id="MathJax-Span-926">=</span><span id="MathJax-Span-927"><span><span><span id="MathJax-Span-928">∑</span><span></span></span><span><span id="MathJax-Span-929"><span id="MathJax-Span-930"><span id="MathJax-Span-931">i</span><span id="MathJax-Span-932">=</span><span id="MathJax-Span-933">1</span></span></span><span></span></span><span><span id="MathJax-Span-934"><span id="MathJax-Span-935"><span id="MathJax-Span-936">c</span></span></span><span></span></span></span></span><span id="MathJax-Span-937"><span><span><span id="MathJax-Span-938">N<span></span></span><span></span></span><span><span id="MathJax-Span-939"><span id="MathJax-Span-940"><span id="MathJax-Span-941">i</span></span></span><span></span></span></span></span><span id="MathJax-Span-942">(</span><span id="MathJax-Span-943"><span id="MathJax-Span-944"><span id="MathJax-Span-945"><span><span><span id="MathJax-Span-946"><span id="MathJax-Span-947">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-948"></span><span id="MathJax-Span-949"><span><span><span id="MathJax-Span-950"><span id="MathJax-Span-951"><span id="MathJax-Span-952">m</span></span></span><span></span></span><span><span id="MathJax-Span-953">i</span><span></span></span></span></span><span id="MathJax-Span-954">−</span><span id="MathJax-Span-955"><span id="MathJax-Span-956"><span id="MathJax-Span-957"><span><span><span id="MathJax-Span-958"><span id="MathJax-Span-959">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-960"></span><span id="MathJax-Span-961"><span id="MathJax-Span-962"><span id="MathJax-Span-963">m</span></span></span><span id="MathJax-Span-964">)</span><span id="MathJax-Span-965">(</span><span id="MathJax-Span-966"><span id="MathJax-Span-967"><span id="MathJax-Span-968"><span><span><span id="MathJax-Span-969"><span id="MathJax-Span-970">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-971"></span><span id="MathJax-Span-972"><span><span><span id="MathJax-Span-973"><span id="MathJax-Span-974"><span id="MathJax-Span-975">m</span></span></span><span></span></span><span><span id="MathJax-Span-976">i</span><span></span></span></span></span><span id="MathJax-Span-977">−</span><span id="MathJax-Span-978"><span id="MathJax-Span-979"><span id="MathJax-Span-980"><span><span><span id="MathJax-Span-981"><span id="MathJax-Span-982">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-983"></span><span id="MathJax-Span-984"><span id="MathJax-Span-985"><span id="MathJax-Span-986">m</span></span></span><span id="MathJax-Span-987"><span><span><span id="MathJax-Span-988">)</span><span></span></span><span><span id="MathJax-Span-989">T<span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>S</mi><mi>B</mi></msub><mo>=</mo><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>c</mi></mrow></munderover><msub><mi>N</mi><mrow><mi>i</mi></mrow></msub><mo stretchy="false">(</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><mo>−</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>m</mi></mrow><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mi>i</mi></msub><mo>−</mo><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>m</mi></mrow><msup><mo stretchy="false">)</mo><mi>T</mi></msup></math></span></span></p>

<p>where<br>
 <span id="MathJax-Element-46-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-990"><span><span><span id="MathJax-Span-991"><span id="MathJax-Span-992"><span id="MathJax-Span-993"><span id="MathJax-Span-994"><span><span><span id="MathJax-Span-995"><span id="MathJax-Span-996">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-997"></span><span id="MathJax-Span-998"><span id="MathJax-Span-999"><span id="MathJax-Span-1000">m</span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>m</mi></mrow></math></span></span> is the overall mean, and <span id="MathJax-Element-47-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1001"><span><span><span id="MathJax-Span-1002"><span id="MathJax-Span-1003"><span id="MathJax-Span-1004"><span id="MathJax-Span-1005"><span><span><span id="MathJax-Span-1006"><span id="MathJax-Span-1007">m</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1008"></span><span id="MathJax-Span-1009"><span><span><span id="MathJax-Span-1010"><span id="MathJax-Span-1011"><span id="MathJax-Span-1012">m</span></span></span><span></span></span><span><span id="MathJax-Span-1013"><span id="MathJax-Span-1014"><span id="MathJax-Span-1015">i</span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>m</mi></mpadded></mrow><mspace width="1px"></mspace><msub><mrow><mi>m</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span></span> and <span id="MathJax-Element-48-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1016"><span><span><span id="MathJax-Span-1017"><span id="MathJax-Span-1018"><span><span><span id="MathJax-Span-1019">N<span></span></span><span></span></span><span><span id="MathJax-Span-1020"><span id="MathJax-Span-1021"><span id="MathJax-Span-1022">i</span></span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mrow><mi>i</mi></mrow></msub></math></span></span> are the sample mean and sizes of the respective classes.</p>

<div><div><pre><code><span>overall_mean</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>

<span>S_B</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>4</span><span>,</span><span>4</span><span>))</span>
<span>for</span> <span>i</span><span>,</span><span>mean_vec</span> <span>in</span> <span>enumerate</span><span>(</span><span>mean_vectors</span><span>):</span>  
    <span>n</span> <span>=</span> <span>X</span><span>[</span><span>y</span><span>==</span><span>i</span><span>+</span><span>1</span><span>,:]</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>mean_vec</span> <span>=</span> <span>mean_vec</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>)</span> <span># make column vector</span>
    <span>overall_mean</span> <span>=</span> <span>overall_mean</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>)</span> <span># make column vector</span>
    <span>S_B</span> <span>+=</span> <span>n</span> <span>*</span> <span>(</span><span>mean_vec</span> <span>-</span> <span>overall_mean</span><span>)</span><span>.</span><span>dot</span><span>((</span><span>mean_vec</span> <span>-</span> <span>overall_mean</span><span>)</span><span>.</span><span>T</span><span>)</span>

<span>print</span><span>(</span><span>'between-class Scatter Matrix:</span><span>\n</span><span>'</span><span>,</span> <span>S_B</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>between-class Scatter Matrix:
 [[  63.2121  -19.534   165.1647   71.3631]
 [ -19.534    10.9776  -56.0552  -22.4924]
 [ 165.1647  -56.0552  436.6437  186.9081]
 [  71.3631  -22.4924  186.9081   80.6041]]
</code></pre></div></div>

<h3 id="step-3-solving-the-generalized-eigenvalue-problem-for-the-matrix-s_w-1s_b">Step 3: Solving the generalized eigenvalue problem for the matrix <span id="MathJax-Element-49-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1023"><span><span><span id="MathJax-Span-1024"><span id="MathJax-Span-1025"><span><span><span id="MathJax-Span-1026">S<span></span></span><span></span></span><span><span id="MathJax-Span-1027"><span id="MathJax-Span-1028"><span id="MathJax-Span-1029">−</span><span id="MathJax-Span-1030">1</span></span></span><span></span></span><span><span id="MathJax-Span-1031"><span id="MathJax-Span-1032"><span id="MathJax-Span-1033">W<span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-1034"><span><span><span id="MathJax-Span-1035">S<span></span></span><span></span></span><span><span id="MathJax-Span-1036">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>S</mi><mrow><mi>W</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>S</mi><mi>B</mi></msub></math></span></span><a href="#step-3-solving-the-generalized-eigenvalue-problem-for-the-matrix-s_w-1s_b" aria-label="Anchor link for: step 3 solving the generalized eigenvalue problem for the matrix s_w 1s_b" data-anchorjs-icon=""></a></h3>

<p>Next, we will solve the generalized eigenvalue problem for the matrix <span id="MathJax-Element-50-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1037"><span><span><span id="MathJax-Span-1038"><span id="MathJax-Span-1039"><span><span><span id="MathJax-Span-1040">S<span></span></span><span></span></span><span><span id="MathJax-Span-1041"><span id="MathJax-Span-1042"><span id="MathJax-Span-1043">−</span><span id="MathJax-Span-1044">1</span></span></span><span></span></span><span><span id="MathJax-Span-1045"><span id="MathJax-Span-1046"><span id="MathJax-Span-1047">W<span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-1048"><span><span><span id="MathJax-Span-1049">S<span></span></span><span></span></span><span><span id="MathJax-Span-1050">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>S</mi><mrow><mi>W</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>S</mi><mi>B</mi></msub></math></span></span> to obtain the linear discriminants.</p>

<div><div><pre><code><span>eig_vals</span><span>,</span> <span>eig_vecs</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>eig</span><span>(</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>inv</span><span>(</span><span>S_W</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>S_B</span><span>))</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span><span>eig_vals</span><span>)):</span>
    <span>eigvec_sc</span> <span>=</span> <span>eig_vecs</span><span>[:,</span><span>i</span><span>]</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>)</span>   
    <span>print</span><span>(</span><span>'</span><span>\n</span><span>Eigenvector {}: </span><span>\n</span><span>{}'</span><span>.</span><span>format</span><span>(</span><span>i</span><span>+</span><span>1</span><span>,</span> <span>eigvec_sc</span><span>.</span><span>real</span><span>))</span>
    <span>print</span><span>(</span><span>'Eigenvalue {:}: {:.2e}'</span><span>.</span><span>format</span><span>(</span><span>i</span><span>+</span><span>1</span><span>,</span> <span>eig_vals</span><span>[</span><span>i</span><span>]</span><span>.</span><span>real</span><span>))</span>
</code></pre></div></div>

<div><div><pre><code>Eigenvector 1:
[[-0.2049]
 [-0.3871]
 [ 0.5465]
 [ 0.7138]]
Eigenvalue 1: 3.23e+01

Eigenvector 2:
[[-0.009 ]
 [-0.589 ]
 [ 0.2543]
 [-0.767 ]]
Eigenvalue 2: 2.78e-01

Eigenvector 3:
[[ 0.179 ]
 [-0.3178]
 [-0.3658]
 [ 0.6011]]
Eigenvalue 3: -4.02e-17

Eigenvector 4:
[[ 0.179 ]
 [-0.3178]
 [-0.3658]
 [ 0.6011]]
Eigenvalue 4: -4.02e-17
</code></pre></div></div>

<p><strong>Note</strong></p>

<p>Depending on which version of NumPy and LAPACK we are using, we may obtain the matrix <span id="MathJax-Element-51-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1051"><span><span><span id="MathJax-Span-1052"><span id="MathJax-Span-1053"><span id="MathJax-Span-1054"><span id="MathJax-Span-1055">W</span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">W</mi></mrow></math></span></span> with its signs flipped. Please note that this is not an issue; if <span id="MathJax-Element-52-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1056"><span><span><span id="MathJax-Span-1057"><span id="MathJax-Span-1058"><span id="MathJax-Span-1059"><span id="MathJax-Span-1060">v</span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">v</mi></mrow></math></span></span> is an eigenvector of a matrix <span id="MathJax-Element-53-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x03A3;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1061"><span><span><span id="MathJax-Span-1062"><span id="MathJax-Span-1063">Σ</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Σ</mi></math></span></span>, we have</p>

<p><span id="MathJax-Element-54-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x03A3;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1064"><span><span><span id="MathJax-Span-1065"><span id="MathJax-Span-1066">Σ</span><span id="MathJax-Span-1067"><span id="MathJax-Span-1068"><span id="MathJax-Span-1069">v</span></span></span><span id="MathJax-Span-1070">=</span><span id="MathJax-Span-1071">λ</span><span id="MathJax-Span-1072"><span id="MathJax-Span-1073"><span id="MathJax-Span-1074">v</span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Σ</mi><mrow><mi mathvariant="bold">v</mi></mrow><mo>=</mo><mi>λ</mi><mrow><mi mathvariant="bold">v</mi></mrow></math></span></span>.</p>

<p>Here, <span id="MathJax-Element-55-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1075"><span><span><span id="MathJax-Span-1076"><span id="MathJax-Span-1077">λ</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>λ</mi></math></span></span> is the eigenvalue, and <span id="MathJax-Element-56-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1078"><span><span><span id="MathJax-Span-1079"><span id="MathJax-Span-1080"><span id="MathJax-Span-1081"><span id="MathJax-Span-1082">v</span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">v</mi></mrow></math></span></span> is also an eigenvector that thas the same eigenvalue, since</p>

<p><span id="MathJax-Element-57-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;S&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;g&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo mathvariant=&quot;bold&quot;&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x03A3;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1083"><span><span><span id="MathJax-Span-1084"><span id="MathJax-Span-1085"><span id="MathJax-Span-1086"><span id="MathJax-Span-1087">S</span><span id="MathJax-Span-1088">i</span><span id="MathJax-Span-1089">g</span><span id="MathJax-Span-1090">m</span><span id="MathJax-Span-1091">a</span></span></span><span id="MathJax-Span-1092">(</span><span id="MathJax-Span-1093">−</span><span id="MathJax-Span-1094"><span id="MathJax-Span-1095"><span id="MathJax-Span-1096">v</span></span></span><span id="MathJax-Span-1097">)</span><span id="MathJax-Span-1098">=</span><span id="MathJax-Span-1099">−</span><span id="MathJax-Span-1100"><span id="MathJax-Span-1101"><span id="MathJax-Span-1102">−</span><span id="MathJax-Span-1103">v</span></span></span><span id="MathJax-Span-1104">Σ</span><span id="MathJax-Span-1105">=</span><span id="MathJax-Span-1106">−</span><span id="MathJax-Span-1107">λ</span><span id="MathJax-Span-1108"><span id="MathJax-Span-1109"><span id="MathJax-Span-1110">v</span></span></span><span id="MathJax-Span-1111">=</span><span id="MathJax-Span-1112">λ</span><span id="MathJax-Span-1113">(</span><span id="MathJax-Span-1114">−</span><span id="MathJax-Span-1115"><span id="MathJax-Span-1116"><span id="MathJax-Span-1117">v</span></span></span><span id="MathJax-Span-1118">)</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">S</mi><mi mathvariant="bold">i</mi><mi mathvariant="bold">g</mi><mi mathvariant="bold">m</mi><mi mathvariant="bold">a</mi></mrow><mo stretchy="false">(</mo><mo>−</mo><mrow><mi mathvariant="bold">v</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mrow><mo mathvariant="bold">−</mo><mi mathvariant="bold">v</mi></mrow><mi mathvariant="normal">Σ</mi><mo>=</mo><mo>−</mo><mi>λ</mi><mrow><mi mathvariant="bold">v</mi></mrow><mo>=</mo><mi>λ</mi><mo stretchy="false">(</mo><mo>−</mo><mrow><mi mathvariant="bold">v</mi></mrow><mo stretchy="false">)</mo></math></span></span>.</p>

<p>After this decomposition of our square matrix into eigenvectors and 
eigenvalues, let us briefly recapitulate how we can interpret those 
results. As we remember from our first linear algebra class in high 
school or college, both eigenvectors and eigenvalues are providing us 
with information about the distortion of a linear transformation: The 
eigenvectors are basically the direction of this distortion, and the 
eigenvalues are the scaling factor for the eigenvectors that describing 
the magnitude of the distortion.</p>

<p>If we are performing the LDA for dimensionality reduction, the 
eigenvectors are important since they will form the new axes of our new 
feature subspace; the associated eigenvalues are of particular interest 
since they will tell us how “informative” the new “axes” are.</p>

<p>Let us briefly double-check our calculation and talk more about the eigenvalues in the next section.</p>

<h4 id="checking-the-eigenvector-eigenvalue-calculation">Checking the eigenvector-eigenvalue calculation<a href="#checking-the-eigenvector-eigenvalue-calculation" aria-label="Anchor link for: checking the eigenvector eigenvalue calculation" data-anchorjs-icon=""></a></h4>

<p>A quick check that the eigenvector-eigenvalue calculation is correct and satisfy the equation:</p>

<p><span id="MathJax-Element-58-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1119"><span><span><span id="MathJax-Span-1120"><span id="MathJax-Span-1121"><span id="MathJax-Span-1122"><span id="MathJax-Span-1123"><span><span><span id="MathJax-Span-1124"><span id="MathJax-Span-1125">A</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1126"></span><span id="MathJax-Span-1127"><span id="MathJax-Span-1128"><span id="MathJax-Span-1129">A</span></span></span><span id="MathJax-Span-1130"><span id="MathJax-Span-1131"><span id="MathJax-Span-1132"><span><span><span id="MathJax-Span-1133"><span id="MathJax-Span-1134">v</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1135"></span><span id="MathJax-Span-1136"><span id="MathJax-Span-1137"><span id="MathJax-Span-1138">v</span></span></span><span id="MathJax-Span-1139">=</span><span id="MathJax-Span-1140">λ</span><span id="MathJax-Span-1141"><span id="MathJax-Span-1142"><span id="MathJax-Span-1143"><span><span><span id="MathJax-Span-1144"><span id="MathJax-Span-1145">v</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1146"></span><span id="MathJax-Span-1147"><span id="MathJax-Span-1148"><span id="MathJax-Span-1149">v</span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mpadded width="0"><mi>A</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>A</mi></mrow><mrow><mpadded width="0"><mi>v</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>v</mi></mrow><mo>=</mo><mi>λ</mi><mrow><mpadded width="0"><mi>v</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>v</mi></mrow></math></span></span></p>

<p>where<br>
<span id="MathJax-Element-59-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;mspace linebreak=&quot;newline&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mtext&gt;Eigenvector&lt;/mtext&gt;&lt;mspace linebreak=&quot;newline&quot; /&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mspace width=&quot;thickmathspace&quot; /&gt;&lt;mtext&gt;Eigenvalue&lt;/mtext&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1150"><span><span><span id="MathJax-Span-1151"><span><span><span id="MathJax-Span-1152"><span id="MathJax-Span-1153"><span id="MathJax-Span-1154"><span><span><span id="MathJax-Span-1155"><span id="MathJax-Span-1156">A</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1157"></span><span id="MathJax-Span-1158"><span id="MathJax-Span-1159"><span id="MathJax-Span-1160">A</span></span></span><span id="MathJax-Span-1161">=</span><span id="MathJax-Span-1162"><span><span><span id="MathJax-Span-1163">S<span></span></span><span></span></span><span><span id="MathJax-Span-1164"><span id="MathJax-Span-1165"><span id="MathJax-Span-1166">−</span><span id="MathJax-Span-1167">1</span></span></span><span></span></span><span><span id="MathJax-Span-1168"><span id="MathJax-Span-1169"><span id="MathJax-Span-1170">W<span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-1171"><span><span><span id="MathJax-Span-1172">S<span></span></span><span></span></span><span><span id="MathJax-Span-1173">B</span><span></span></span></span></span><span></span></span><span><span id="MathJax-Span-1174"></span><span id="MathJax-Span-1175"><span id="MathJax-Span-1176"><span id="MathJax-Span-1177"><span><span><span id="MathJax-Span-1178"><span id="MathJax-Span-1179">v</span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1180"></span><span id="MathJax-Span-1181"><span id="MathJax-Span-1182"><span id="MathJax-Span-1183">v</span></span></span><span id="MathJax-Span-1184">=</span><span id="MathJax-Span-1185"></span><span id="MathJax-Span-1186">Eigenvector</span><span></span></span><span><span id="MathJax-Span-1187"></span><span id="MathJax-Span-1188">λ</span><span id="MathJax-Span-1189">=</span><span id="MathJax-Span-1190"></span><span id="MathJax-Span-1191">Eigenvalue</span><span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>A</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>A</mi></mrow><mo>=</mo><msubsup><mi>S</mi><mrow><mi>W</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>S</mi><mi>B</mi></msub><mspace linebreak="newline"></mspace><mrow><mpadded width="0"><mi>v</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>v</mi></mrow><mo>=</mo><mspace width="thickmathspace"></mspace><mtext>Eigenvector</mtext><mspace linebreak="newline"></mspace><mi>λ</mi><mo>=</mo><mspace width="thickmathspace"></mspace><mtext>Eigenvalue</mtext></math></span></span></p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span><span>eig_vals</span><span>)):</span>
    <span>eigv</span> <span>=</span> <span>eig_vecs</span><span>[:,</span><span>i</span><span>]</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>)</span>
    <span>np</span><span>.</span><span>testing</span><span>.</span><span>assert_array_almost_equal</span><span>(</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>inv</span><span>(</span><span>S_W</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>S_B</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>eigv</span><span>),</span>
                                         <span>eig_vals</span><span>[</span><span>i</span><span>]</span> <span>*</span> <span>eigv</span><span>,</span>
                                         <span>decimal</span><span>=</span><span>6</span><span>,</span> <span>err_msg</span><span>=</span><span>''</span><span>,</span> <span>verbose</span><span>=</span><span>True</span><span>)</span>
<span>print</span><span>(</span><span>'ok'</span><span>)</span>
</code></pre></div></div>



<h3 id="step-4-selecting-linear-discriminants-for-the-new-feature-subspace">Step 4: Selecting linear discriminants for the new feature subspace<a href="#step-4-selecting-linear-discriminants-for-the-new-feature-subspace" aria-label="Anchor link for: step 4 selecting linear discriminants for the new feature subspace" data-anchorjs-icon=""></a></h3>

<h4 id="41-sorting-the-eigenvectors-by-decreasing-eigenvalues">4.1. Sorting the eigenvectors by decreasing eigenvalues<a href="#41-sorting-the-eigenvectors-by-decreasing-eigenvalues" aria-label="Anchor link for: 41 sorting the eigenvectors by decreasing eigenvalues" data-anchorjs-icon=""></a></h4>

<p>Remember from the introduction that we are not only interested in 
merely projecting the data into a subspace that improves the class 
separability, but also reduces the dimensionality of our feature space, 
(where the eigenvectors will form the axes of this new feature 
subspace).</p>

<p>However, the eigenvectors only define the directions of the new axis, since they have all the same unit length 1.</p>

<p>So, in order to decide which eigenvector(s) we want to drop for our 
lower-dimensional subspace, we have to take a look at the corresponding 
eigenvalues of the eigenvectors. Roughly speaking, the eigenvectors with
 the lowest eigenvalues bear the least information about the 
distribution of the data, and those are the ones we want to drop.<br>
The common approach is to rank the eigenvectors from highest to lowest corresponding eigenvalue and choose the top <span id="MathJax-Element-60-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1192"><span><span><span id="MathJax-Span-1193"><span id="MathJax-Span-1194">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span> eigenvectors.</p>

<div><div><pre><code><span># Make a list of (eigenvalue, eigenvector) tuples</span>
<span>eig_pairs</span> <span>=</span> <span>[(</span><span>np</span><span>.</span><span>abs</span><span>(</span><span>eig_vals</span><span>[</span><span>i</span><span>]),</span> <span>eig_vecs</span><span>[:,</span><span>i</span><span>])</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span><span>eig_vals</span><span>))]</span>

<span># Sort the (eigenvalue, eigenvector) tuples from high to low</span>
<span>eig_pairs</span> <span>=</span> <span>sorted</span><span>(</span><span>eig_pairs</span><span>,</span> <span>key</span><span>=</span><span>lambda</span> <span>k</span><span>:</span> <span>k</span><span>[</span><span>0</span><span>],</span> <span>reverse</span><span>=</span><span>True</span><span>)</span>

<span># Visually confirm that the list is correctly sorted by decreasing eigenvalues</span>

<span>print</span><span>(</span><span>'Eigenvalues in decreasing order:</span><span>\n</span><span>'</span><span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>eig_pairs</span><span>:</span>
    <span>print</span><span>(</span><span>i</span><span>[</span><span>0</span><span>])</span>
</code></pre></div></div>

<div><div><pre><code>Eigenvalues in decreasing order:

32.2719577997
0.27756686384
5.71450476746e-15
5.71450476746e-15
</code></pre></div></div>

<p><strong>Note</strong></p>

<p>If we take a look at the eigenvalues, we can already see that 2 
eigenvalues are close to 0. The reason why these are close to 0 is not 
that they are not informative but it’s due to floating-point 
imprecision. In fact, these two last eigenvalues should be exactly zero:
 In LDA, the number of linear discriminants is at most <span id="MathJax-Element-61-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1195"><span><span><span id="MathJax-Span-1196"><span id="MathJax-Span-1197">c</span><span id="MathJax-Span-1198">−</span><span id="MathJax-Span-1199">1</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>c</mi><mo>−</mo><mn>1</mn></math></span></span> where <span id="MathJax-Element-62-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1200"><span><span><span id="MathJax-Span-1201"><span id="MathJax-Span-1202">c</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>c</mi></math></span></span> is the number of class labels, since the in-between scatter matrix <span id="MathJax-Element-63-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1203"><span><span><span id="MathJax-Span-1204"><span id="MathJax-Span-1205"><span><span><span id="MathJax-Span-1206">S<span></span></span><span></span></span><span><span id="MathJax-Span-1207">B</span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>B</mi></msub></math></span></span> is the sum of <span id="MathJax-Element-64-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1208"><span><span><span id="MathJax-Span-1209"><span id="MathJax-Span-1210">c</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>c</mi></math></span></span>
 matrices with rank 1 or less. Note that in the rare case of perfect 
collinearity (all aligned sample points fall on a straight line), the 
covariance matrix would have rank one, which would result in only one 
eigenvector with a nonzero eigenvalue.</p>

<p>Now, let’s express the “explained variance” as percentage:</p>

<div><div><pre><code><span>print</span><span>(</span><span>'Variance explained:</span><span>\n</span><span>'</span><span>)</span>
<span>eigv_sum</span> <span>=</span> <span>sum</span><span>(</span><span>eig_vals</span><span>)</span>
<span>for</span> <span>i</span><span>,</span><span>j</span> <span>in</span> <span>enumerate</span><span>(</span><span>eig_pairs</span><span>):</span>
    <span>print</span><span>(</span><span>'eigenvalue {0:}: {1:.2</span><span>%</span><span>}'</span><span>.</span><span>format</span><span>(</span><span>i</span><span>+</span><span>1</span><span>,</span> <span>(</span><span>j</span><span>[</span><span>0</span><span>]</span><span>/</span><span>eigv_sum</span><span>)</span><span>.</span><span>real</span><span>))</span>
</code></pre></div></div>

<div><div><pre><code>Variance explained:

eigenvalue 1: 99.15%
eigenvalue 2: 0.85%
eigenvalue 3: 0.00%
eigenvalue 4: 0.00%
</code></pre></div></div>

<p>The first eigenpair is by far the most informative one, and we won’t 
loose much information if we would form a 1D-feature spaced based on 
this eigenpair.</p>

<h4 id="42-choosing-k-eigenvectors-with-the-largest-eigenvalues">4.2. Choosing <em>k</em> eigenvectors with the largest eigenvalues<a href="#42-choosing-k-eigenvectors-with-the-largest-eigenvalues" aria-label="Anchor link for: 42 choosing k eigenvectors with the largest eigenvalues" data-anchorjs-icon=""></a></h4>

<p>After sorting the eigenpairs by decreasing eigenvalues, it is now time to construct our <span id="MathJax-Element-65-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1211"><span><span><span id="MathJax-Span-1212"><span id="MathJax-Span-1213">k</span><span id="MathJax-Span-1214">×</span><span id="MathJax-Span-1215">d<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>×</mo><mi>d</mi></math></span></span>-dimensional eigenvector matrix <span id="MathJax-Element-66-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1216"><span><span><span id="MathJax-Span-1217"><span id="MathJax-Span-1218"><span id="MathJax-Span-1219"><span id="MathJax-Span-1220"><span><span><span id="MathJax-Span-1221"><span id="MathJax-Span-1222">W<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1223"></span><span id="MathJax-Span-1224"><span id="MathJax-Span-1225"><span id="MathJax-Span-1226">W<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>W</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>W</mi></mrow></math></span></span> (here <span id="MathJax-Element-67-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1227"><span><span><span id="MathJax-Span-1228"><span id="MathJax-Span-1229">4</span><span id="MathJax-Span-1230">×</span><span id="MathJax-Span-1231">2</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mo>×</mo><mn>2</mn></math></span></span>:
 based on the 2 most informative eigenpairs) and thereby reducing the 
initial 4-dimensional feature space into a 2-dimensional feature 
subspace.</p>

<div><div><pre><code><span>W</span> <span>=</span> <span>np</span><span>.</span><span>hstack</span><span>((</span><span>eig_pairs</span><span>[</span><span>0</span><span>][</span><span>1</span><span>]</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>),</span> <span>eig_pairs</span><span>[</span><span>1</span><span>][</span><span>1</span><span>]</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span><span>1</span><span>)))</span>
<span>print</span><span>(</span><span>'Matrix W:</span><span>\n</span><span>'</span><span>,</span> <span>W</span><span>.</span><span>real</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>Matrix W:
 [[-0.2049 -0.009 ]
 [-0.3871 -0.589 ]
 [ 0.5465  0.2543]
 [ 0.7138 -0.767 ]]
</code></pre></div></div>

<h2 id="step-5-transforming-the-samples-onto-the-new-subspace">Step 5: Transforming the samples onto the new subspace<a href="#step-5-transforming-the-samples-onto-the-new-subspace" aria-label="Anchor link for: step 5 transforming the samples onto the new subspace" data-anchorjs-icon=""></a></h2>

<p>In the last step, we use the <span id="MathJax-Element-68-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1232"><span><span><span id="MathJax-Span-1233"><span id="MathJax-Span-1234">4</span><span id="MathJax-Span-1235">×</span><span id="MathJax-Span-1236">2</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mo>×</mo><mn>2</mn></math></span></span>-dimensional matrix <span id="MathJax-Element-69-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1237"><span><span><span id="MathJax-Span-1238"><span id="MathJax-Span-1239"><span id="MathJax-Span-1240"><span id="MathJax-Span-1241"><span><span><span id="MathJax-Span-1242"><span id="MathJax-Span-1243">W<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1244"></span><span id="MathJax-Span-1245"><span id="MathJax-Span-1246"><span id="MathJax-Span-1247">W<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>W</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>W</mi></mrow></math></span></span> that we just computed to transform our samples onto the new subspace via the equation</p>

<p><span id="MathJax-Element-70-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1248"><span><span><span id="MathJax-Span-1249"><span id="MathJax-Span-1250"><span id="MathJax-Span-1251"><span id="MathJax-Span-1252"><span><span><span id="MathJax-Span-1253"><span id="MathJax-Span-1254">Y<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1255"></span><span id="MathJax-Span-1256"><span id="MathJax-Span-1257"><span id="MathJax-Span-1258">Y<span></span></span></span></span><span id="MathJax-Span-1259">=</span><span id="MathJax-Span-1260"><span id="MathJax-Span-1261"><span id="MathJax-Span-1262"><span><span><span id="MathJax-Span-1263"><span id="MathJax-Span-1264">X<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1265"></span><span id="MathJax-Span-1266"><span id="MathJax-Span-1267"><span id="MathJax-Span-1268">X<span></span></span></span></span><span id="MathJax-Span-1269">×</span><span id="MathJax-Span-1270"><span id="MathJax-Span-1271"><span id="MathJax-Span-1272"><span><span><span id="MathJax-Span-1273"><span id="MathJax-Span-1274">W<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1275"></span><span id="MathJax-Span-1276"><span id="MathJax-Span-1277"><span id="MathJax-Span-1278">W<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>Y</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>Y</mi></mrow><mo>=</mo><mrow><mpadded width="0"><mi>X</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>X</mi></mrow><mo>×</mo><mrow><mpadded width="0"><mi>W</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>W</mi></mrow></math></span></span>.</p>

<p>(where <span id="MathJax-Element-71-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1279"><span><span><span id="MathJax-Span-1280"><span id="MathJax-Span-1281"><span id="MathJax-Span-1282"><span id="MathJax-Span-1283"><span><span><span id="MathJax-Span-1284"><span id="MathJax-Span-1285">X<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1286"></span><span id="MathJax-Span-1287"><span id="MathJax-Span-1288"><span id="MathJax-Span-1289">X<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>X</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>X</mi></mrow></math></span></span> is a <span id="MathJax-Element-72-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1290"><span><span><span id="MathJax-Span-1291"><span id="MathJax-Span-1292">n</span><span id="MathJax-Span-1293">×</span><span id="MathJax-Span-1294">d<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>×</mo><mi>d</mi></math></span></span>-dimensional matrix representing the <span id="MathJax-Element-73-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1295"><span><span><span id="MathJax-Span-1296"><span id="MathJax-Span-1297">n</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span> samples, and <span id="MathJax-Element-74-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mpadded width=&quot;0&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mpadded&gt;&lt;/mrow&gt;&lt;mspace width=&quot;1px&quot; /&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1298"><span><span><span id="MathJax-Span-1299"><span id="MathJax-Span-1300"><span id="MathJax-Span-1301"><span id="MathJax-Span-1302"><span><span><span id="MathJax-Span-1303"><span id="MathJax-Span-1304">Y<span></span></span></span><span></span></span></span></span></span></span><span id="MathJax-Span-1305"></span><span id="MathJax-Span-1306"><span id="MathJax-Span-1307"><span id="MathJax-Span-1308">Y<span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mpadded width="0"><mi>Y</mi></mpadded></mrow><mspace width="1px"></mspace><mrow><mi>Y</mi></mrow></math></span></span> are the transformed <span id="MathJax-Element-75-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1309"><span><span><span id="MathJax-Span-1310"><span id="MathJax-Span-1311">n</span><span id="MathJax-Span-1312">×</span><span id="MathJax-Span-1313">k</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>×</mo><mi>k</mi></math></span></span>-dimensional samples in the new subspace).</p>

<div><div><pre><code><span>X_lda</span> <span>=</span> <span>X</span><span>.</span><span>dot</span><span>(</span><span>W</span><span>)</span>
<span>assert</span> <span>X_lda</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>150</span><span>,</span><span>2</span><span>),</span> <span>"The matrix is not 150x2 dimensional."</span>
</code></pre></div></div>

<div><div><pre><code><span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>

<span>def</span> <span>plot_step_lda</span><span>():</span>

    <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>111</span><span>)</span>
    <span>for</span> <span>label</span><span>,</span><span>marker</span><span>,</span><span>color</span> <span>in</span> <span>zip</span><span>(</span>
        <span>range</span><span>(</span><span>1</span><span>,</span><span>4</span><span>),(</span><span>'^'</span><span>,</span> <span>'s'</span><span>,</span> <span>'o'</span><span>),(</span><span>'blue'</span><span>,</span> <span>'red'</span><span>,</span> <span>'green'</span><span>)):</span>

        <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>x</span><span>=</span><span>X_lda</span><span>[:,</span><span>0</span><span>]</span><span>.</span><span>real</span><span>[</span><span>y</span> <span>==</span> <span>label</span><span>],</span>
                <span>y</span><span>=</span><span>X_lda</span><span>[:,</span><span>1</span><span>]</span><span>.</span><span>real</span><span>[</span><span>y</span> <span>==</span> <span>label</span><span>],</span>
                <span>marker</span><span>=</span><span>marker</span><span>,</span>
                <span>color</span><span>=</span><span>color</span><span>,</span>
                <span>alpha</span><span>=</span><span>0.5</span><span>,</span>
                <span>label</span><span>=</span><span>label_dict</span><span>[</span><span>label</span><span>]</span>
                <span>)</span>

    <span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>'LD1'</span><span>)</span>
    <span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>'LD2'</span><span>)</span>

    <span>leg</span> <span>=</span> <span>plt</span><span>.</span><span>legend</span><span>(</span><span>loc</span><span>=</span><span>'upper right'</span><span>,</span> <span>fancybox</span><span>=</span><span>True</span><span>)</span>
    <span>leg</span><span>.</span><span>get_frame</span><span>()</span><span>.</span><span>set_alpha</span><span>(</span><span>0.5</span><span>)</span>
    <span>plt</span><span>.</span><span>title</span><span>(</span><span>'LDA: Iris projection onto the first 2 linear discriminants'</span><span>)</span>

    <span># hide axis ticks</span>
    <span>plt</span><span>.</span><span>tick_params</span><span>(</span><span>axis</span><span>=</span><span>"both"</span><span>,</span> <span>which</span><span>=</span><span>"both"</span><span>,</span> <span>bottom</span><span>=</span><span>"off"</span><span>,</span> <span>top</span><span>=</span><span>"off"</span><span>,</span>  
            <span>labelbottom</span><span>=</span><span>"on"</span><span>,</span> <span>left</span><span>=</span><span>"off"</span><span>,</span> <span>right</span><span>=</span><span>"off"</span><span>,</span> <span>labelleft</span><span>=</span><span>"on"</span><span>)</span>

    <span># remove axis spines</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"top"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>  
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"right"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"bottom"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"left"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>    

    <span>plt</span><span>.</span><span>grid</span><span>()</span>
    <span>plt</span><span>.</span><span>tight_layout</span>
    <span>plt</span><span>.</span><span>show</span><span>()</span>

<span>plot_step_lda</span><span>()</span>
</code></pre></div></div>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_120_0.png" alt="png"></p>

<p>The scatter plot above represents our new feature subspace that we 
constructed via LDA. We can see that the first linear discriminant “LD1”
 separates the classes quite nicely. However, the second discriminant, 
“LD2”, does not add much valuable information, which we’ve already 
concluded when we looked at the ranked eigenvalues is step 4.</p>

<h2 id="a-comparison-of-pca-and-lda">A comparison of PCA and LDA<a href="#a-comparison-of-pca-and-lda" aria-label="Anchor link for: a comparison of pca and lda" data-anchorjs-icon=""></a></h2>

<p>In order to compare the feature subspace that we obtained via the Linear Discriminant Analysis, we will use the <code>PCA</code> class from the <code>scikit-learn</code> machine-learning library. The documentation can be found here:<br>
<a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</a>.</p>

<p>For our convenience, we can directly specify to how many components we want to retain in our input dataset via the <code>n_components</code> parameter.</p>

<div><div><pre><code>n_components : int, None or string

Number of components to keep. if n_components is not set all components are kept:
    n_components == min(n_samples, n_features)
    if n_components == ‘mle’, Minka’s MLE is used to guess the dimension if 0 &lt; n_components &lt; 1,
    select the number of components such that the amount of variance that needs to be explained
    is greater than the percentage specified by n_components
</code></pre></div></div>

<p>But before we skip to the results of the respective linear 
transformations, let us quickly recapitulate the purposes of PCA and 
LDA: PCA finds the axes with maximum variance for the whole data set 
where LDA tries to find the axes for best class seperability. In 
practice, often a LDA is done followed by a PCA for dimensionality 
reduction.</p>

<p><img src="Linear%20Discriminant%20Analysis_files/lda_1.png" alt="" moz-reader-center="true"></p>

<div><div><pre><code><span>from</span> <span>sklearn.decomposition</span> <span>import</span> <span>PCA</span> <span>as</span> <span>sklearnPCA</span>

<span>sklearn_pca</span> <span>=</span> <span>sklearnPCA</span><span>(</span><span>n_components</span><span>=</span><span>2</span><span>)</span>
<span>X_pca</span> <span>=</span> <span>sklearn_pca</span><span>.</span><span>fit_transform</span><span>(</span><span>X</span><span>)</span>

<span>def</span> <span>plot_pca</span><span>():</span>

    <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>111</span><span>)</span>

    <span>for</span> <span>label</span><span>,</span><span>marker</span><span>,</span><span>color</span> <span>in</span> <span>zip</span><span>(</span>
        <span>range</span><span>(</span><span>1</span><span>,</span><span>4</span><span>),(</span><span>'^'</span><span>,</span> <span>'s'</span><span>,</span> <span>'o'</span><span>),(</span><span>'blue'</span><span>,</span> <span>'red'</span><span>,</span> <span>'green'</span><span>)):</span>

        <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>x</span><span>=</span><span>X_pca</span><span>[:,</span><span>0</span><span>][</span><span>y</span> <span>==</span> <span>label</span><span>],</span>
                <span>y</span><span>=</span><span>X_pca</span><span>[:,</span><span>1</span><span>][</span><span>y</span> <span>==</span> <span>label</span><span>],</span>
                <span>marker</span><span>=</span><span>marker</span><span>,</span>
                <span>color</span><span>=</span><span>color</span><span>,</span>
                <span>alpha</span><span>=</span><span>0.5</span><span>,</span>
                <span>label</span><span>=</span><span>label_dict</span><span>[</span><span>label</span><span>]</span>
                <span>)</span>

    <span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>'PC1'</span><span>)</span>
    <span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>'PC2'</span><span>)</span>

    <span>leg</span> <span>=</span> <span>plt</span><span>.</span><span>legend</span><span>(</span><span>loc</span><span>=</span><span>'upper right'</span><span>,</span> <span>fancybox</span><span>=</span><span>True</span><span>)</span>
    <span>leg</span><span>.</span><span>get_frame</span><span>()</span><span>.</span><span>set_alpha</span><span>(</span><span>0.5</span><span>)</span>
    <span>plt</span><span>.</span><span>title</span><span>(</span><span>'PCA: Iris projection onto the first 2 principal components'</span><span>)</span>

    <span># hide axis ticks</span>
    <span>plt</span><span>.</span><span>tick_params</span><span>(</span><span>axis</span><span>=</span><span>"both"</span><span>,</span> <span>which</span><span>=</span><span>"both"</span><span>,</span> <span>bottom</span><span>=</span><span>"off"</span><span>,</span> <span>top</span><span>=</span><span>"off"</span><span>,</span>  
            <span>labelbottom</span><span>=</span><span>"on"</span><span>,</span> <span>left</span><span>=</span><span>"off"</span><span>,</span> <span>right</span><span>=</span><span>"off"</span><span>,</span> <span>labelleft</span><span>=</span><span>"on"</span><span>)</span>

    <span># remove axis spines</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"top"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>  
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"right"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"bottom"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"left"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>    

    <span>plt</span><span>.</span><span>tight_layout</span>
    <span>plt</span><span>.</span><span>grid</span><span>()</span>

    <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code><span>plot_pca</span><span>()</span>
<span>plot_step_lda</span><span>()</span>
</code></pre></div></div>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_133_0.png" alt="png"></p>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_133_1.png" alt="png"></p>

<p>The two plots above nicely confirm what we have discussed before: 
Where the PCA accounts for the most variance in the whole dataset, the 
LDA gives us the axes that account for the most variance between the 
individual classes.</p>

<h2 id="lda-via-scikit-learn">LDA via scikit-learn<a href="#lda-via-scikit-learn" aria-label="Anchor link for: lda via scikit learn" data-anchorjs-icon=""></a></h2>

<p>Now, after we have seen how an Linear Discriminant Analysis works 
using a step-by-step approach, there is also a more convenient way to 
achive the same via the <code>LDA</code> class implemented in the <a href="http://scikit-learn.org/stable/"><code>scikit-learn</code></a> machine learning library.</p>

<div><div><pre><code><span>from</span> <span>sklearn.discriminant_analysis</span> <span>import</span> <span>LinearDiscriminantAnalysis</span> <span>as</span> <span>LDA</span>

<span># LDA</span>
<span>sklearn_lda</span> <span>=</span> <span>LDA</span><span>(</span><span>n_components</span><span>=</span><span>2</span><span>)</span>
<span>X_lda_sklearn</span> <span>=</span> <span>sklearn_lda</span><span>.</span><span>fit_transform</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code><span>def</span> <span>plot_scikit_lda</span><span>(</span><span>X</span><span>,</span> <span>title</span><span>):</span>

    <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>111</span><span>)</span>
    <span>for</span> <span>label</span><span>,</span><span>marker</span><span>,</span><span>color</span> <span>in</span> <span>zip</span><span>(</span>
        <span>range</span><span>(</span><span>1</span><span>,</span><span>4</span><span>),(</span><span>'^'</span><span>,</span> <span>'s'</span><span>,</span> <span>'o'</span><span>),(</span><span>'blue'</span><span>,</span> <span>'red'</span><span>,</span> <span>'green'</span><span>)):</span>

        <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>x</span><span>=</span><span>X</span><span>[:,</span><span>0</span><span>][</span><span>y</span> <span>==</span> <span>label</span><span>],</span>
                    <span>y</span><span>=</span><span>X</span><span>[:,</span><span>1</span><span>][</span><span>y</span> <span>==</span> <span>label</span><span>]</span> <span>*</span> <span>-</span><span>1</span><span>,</span> <span># flip the figure</span>
                    <span>marker</span><span>=</span><span>marker</span><span>,</span>
                    <span>color</span><span>=</span><span>color</span><span>,</span>
                    <span>alpha</span><span>=</span><span>0.5</span><span>,</span>
                    <span>label</span><span>=</span><span>label_dict</span><span>[</span><span>label</span><span>])</span>

    <span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>'LD1'</span><span>)</span>
    <span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>'LD2'</span><span>)</span>

    <span>leg</span> <span>=</span> <span>plt</span><span>.</span><span>legend</span><span>(</span><span>loc</span><span>=</span><span>'upper right'</span><span>,</span> <span>fancybox</span><span>=</span><span>True</span><span>)</span>
    <span>leg</span><span>.</span><span>get_frame</span><span>()</span><span>.</span><span>set_alpha</span><span>(</span><span>0.5</span><span>)</span>
    <span>plt</span><span>.</span><span>title</span><span>(</span><span>title</span><span>)</span>

    <span># hide axis ticks</span>
    <span>plt</span><span>.</span><span>tick_params</span><span>(</span><span>axis</span><span>=</span><span>"both"</span><span>,</span> <span>which</span><span>=</span><span>"both"</span><span>,</span> <span>bottom</span><span>=</span><span>"off"</span><span>,</span> <span>top</span><span>=</span><span>"off"</span><span>,</span>  
            <span>labelbottom</span><span>=</span><span>"on"</span><span>,</span> <span>left</span><span>=</span><span>"off"</span><span>,</span> <span>right</span><span>=</span><span>"off"</span><span>,</span> <span>labelleft</span><span>=</span><span>"on"</span><span>)</span>

    <span># remove axis spines</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"top"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>  
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"right"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"bottom"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax</span><span>.</span><span>spines</span><span>[</span><span>"left"</span><span>]</span><span>.</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>    

    <span>plt</span><span>.</span><span>grid</span><span>()</span>
    <span>plt</span><span>.</span><span>tight_layout</span>
    <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code><span>plot_step_lda</span><span>()</span>
<span>plot_scikit_lda</span><span>(</span><span>X_lda_sklearn</span><span>,</span> <span>title</span><span>=</span><span>'Default LDA via scikit-learn'</span><span>)</span>
</code></pre></div></div>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_142_0.png" alt="png"></p>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_142_1.png" alt="png"></p>

<h2 id="a-note-about-standardization">A Note About Standardization<a href="#a-note-about-standardization" aria-label="Anchor link for: a note about standardization" data-anchorjs-icon=""></a></h2>

<p>To follow up on a question that I received recently, I wanted to clarify that feature scaling such as [standardization] does <strong>not</strong>
 change the overall results of an LDA and thus may be optional. Yes, the
 scatter matrices will be different depending on whether the features 
were scaled or not. In addition, the eigenvectors will be different as 
well. However, the important part is that the eigenvalues will be 
exactly the same as well as the final projects – the only difference 
you’ll notice is the scaling of the component axes. This can be shown 
mathematically (I will insert the formulaes some time in future), and 
below is a practical, visual example for demonstration.</p>

<div><div><pre><code><span>%</span><span>matplotlib</span> <span>inline</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'</span><span>,</span> <span>header</span><span>=</span><span>None</span><span>)</span>
<span>df</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>df</span><span>[</span><span>4</span><span>]</span><span>.</span><span>map</span><span>({</span><span>'Iris-setosa'</span><span>:</span><span>0</span><span>,</span> <span>'Iris-versicolor'</span><span>:</span><span>1</span><span>,</span> <span>'Iris-virginica'</span><span>:</span><span>2</span><span>})</span>
<span>df</span><span>.</span><span>tail</span><span>()</span>
</code></pre></div></div>

<div>
<table>
  <thead>
    <tr>
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>145</th>
      <td>6.7</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>146</th>
      <td>6.3</td>
      <td>2.5</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>2</td>
    </tr>
    <tr>
      <th>147</th>
      <td>6.5</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>148</th>
      <td>6.2</td>
      <td>3.4</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>149</th>
      <td>5.9</td>
      <td>3.0</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<p>After loading the dataset, we are going to standardize the columns in <code>X</code>. Standardization implies mean centering and scaling to unit variance:</p>

<p><span id="MathJax-Element-76-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03BC;&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1314"><span><span><span id="MathJax-Span-1315"><span id="MathJax-Span-1316"><span><span><span id="MathJax-Span-1317">x</span><span></span></span><span><span id="MathJax-Span-1318"><span id="MathJax-Span-1319"><span id="MathJax-Span-1320">s</span><span id="MathJax-Span-1321">t</span><span id="MathJax-Span-1322">d<span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-1323">=</span><span id="MathJax-Span-1324"><span><span><span id="MathJax-Span-1325"><span id="MathJax-Span-1326">x</span><span id="MathJax-Span-1327">−</span><span id="MathJax-Span-1328"><span><span><span id="MathJax-Span-1329">μ</span><span></span></span><span><span id="MathJax-Span-1330">x</span><span></span></span></span></span></span><span></span></span><span><span id="MathJax-Span-1331"><span><span><span id="MathJax-Span-1332">σ<span></span></span><span></span></span><span><span id="MathJax-Span-1333">X<span></span></span><span></span></span></span></span><span></span></span><span><span></span><span></span></span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>x</mi><mrow><mi>s</mi><mi>t</mi><mi>d</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>x</mi></msub></mrow><msub><mi>σ</mi><mi>X</mi></msub></mfrac></math></span></span></p>

<p>After standardization, the columns will have zero mean ( <span id="MathJax-Element-77-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03BC;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1334"><span><span><span id="MathJax-Span-1335"><span id="MathJax-Span-1336"><span><span><span id="MathJax-Span-1337">μ</span><span></span></span><span><span id="MathJax-Span-1338"><span id="MathJax-Span-1339"><span id="MathJax-Span-1340"><span><span><span id="MathJax-Span-1341">x</span><span></span></span><span><span id="MathJax-Span-1342"><span id="MathJax-Span-1343"><span id="MathJax-Span-1344">s</span><span id="MathJax-Span-1345">t</span><span id="MathJax-Span-1346">d<span></span></span></span></span><span></span></span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-1347">=</span><span id="MathJax-Span-1348">0</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>μ</mi><mrow><msub><mi>x</mi><mrow><mi>s</mi><mi>t</mi><mi>d</mi></mrow></msub></mrow></msub><mo>=</mo><mn>0</mn></math></span></span> ) and a standard deviation of 1 (<span id="MathJax-Element-78-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1349"><span><span><span id="MathJax-Span-1350"><span id="MathJax-Span-1351"><span><span><span id="MathJax-Span-1352">σ<span></span></span><span></span></span><span><span id="MathJax-Span-1353"><span id="MathJax-Span-1354"><span id="MathJax-Span-1355"><span><span><span id="MathJax-Span-1356">x</span><span></span></span><span><span id="MathJax-Span-1357"><span id="MathJax-Span-1358"><span id="MathJax-Span-1359">s</span><span id="MathJax-Span-1360">t</span><span id="MathJax-Span-1361">d<span></span></span></span></span><span></span></span></span></span></span></span><span></span></span></span></span><span id="MathJax-Span-1362">=</span><span id="MathJax-Span-1363">1</span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>σ</mi><mrow><msub><mi>x</mi><mrow><mi>s</mi><mi>t</mi><mi>d</mi></mrow></msub></mrow></msub><mo>=</mo><mn>1</mn></math></span></span>).</p>

<div><div><pre><code><span>y</span><span>,</span> <span>X</span> <span>=</span> <span>df</span><span>.</span><span>iloc</span><span>[:,</span> <span>4</span><span>]</span><span>.</span><span>values</span><span>,</span> <span>df</span><span>.</span><span>iloc</span><span>[:,</span> <span>0</span><span>:</span><span>4</span><span>]</span><span>.</span><span>values</span>
<span>X_cent</span> <span>=</span> <span>X</span> <span>-</span> <span>X</span><span>.</span><span>mean</span><span>(</span><span>axis</span><span>=</span><span>0</span><span>)</span>
<span>X_std</span> <span>=</span> <span>X_cent</span> <span>/</span> <span>X</span><span>.</span><span>std</span><span>(</span><span>axis</span><span>=</span><span>0</span><span>)</span>
</code></pre></div></div>

<p>Below, I simply copied the individual steps of an LDA, which we discussed previously, into Python functions for convenience.</p>

<div><div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>comp_mean_vectors</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>):</span>
    <span>class_labels</span> <span>=</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>y</span><span>)</span>
    <span>n_classes</span> <span>=</span> <span>class_labels</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>mean_vectors</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>cl</span> <span>in</span> <span>class_labels</span><span>:</span>
        <span>mean_vectors</span><span>.</span><span>append</span><span>(</span><span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>[</span><span>y</span><span>==</span><span>cl</span><span>],</span> <span>axis</span><span>=</span><span>0</span><span>))</span>
    <span>return</span> <span>mean_vectors</span>

<span>def</span> <span>scatter_within</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>):</span>
    <span>class_labels</span> <span>=</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>y</span><span>)</span>
    <span>n_classes</span> <span>=</span> <span>class_labels</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>n_features</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>mean_vectors</span> <span>=</span> <span>comp_mean_vectors</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>)</span>
    <span>S_W</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>n_features</span><span>,</span> <span>n_features</span><span>))</span>
    <span>for</span> <span>cl</span><span>,</span> <span>mv</span> <span>in</span> <span>zip</span><span>(</span><span>class_labels</span><span>,</span> <span>mean_vectors</span><span>):</span>
        <span>class_sc_mat</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>n_features</span><span>,</span> <span>n_features</span><span>))</span>                 
        <span>for</span> <span>row</span> <span>in</span> <span>X</span><span>[</span><span>y</span> <span>==</span> <span>cl</span><span>]:</span>
            <span>row</span><span>,</span> <span>mv</span> <span>=</span> <span>row</span><span>.</span><span>reshape</span><span>(</span><span>n_features</span><span>,</span> <span>1</span><span>),</span> <span>mv</span><span>.</span><span>reshape</span><span>(</span><span>n_features</span><span>,</span> <span>1</span><span>)</span>
            <span>class_sc_mat</span> <span>+=</span> <span>(</span><span>row</span><span>-</span><span>mv</span><span>)</span><span>.</span><span>dot</span><span>((</span><span>row</span><span>-</span><span>mv</span><span>)</span><span>.</span><span>T</span><span>)</span>
        <span>S_W</span> <span>+=</span> <span>class_sc_mat</span>                           
    <span>return</span> <span>S_W</span>

<span>def</span> <span>scatter_between</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>):</span>
    <span>overall_mean</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
    <span>n_features</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>mean_vectors</span> <span>=</span> <span>comp_mean_vectors</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>)</span>    
    <span>S_B</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>n_features</span><span>,</span> <span>n_features</span><span>))</span>
    <span>for</span> <span>i</span><span>,</span> <span>mean_vec</span> <span>in</span> <span>enumerate</span><span>(</span><span>mean_vectors</span><span>):</span>  
        <span>n</span> <span>=</span> <span>X</span><span>[</span><span>y</span><span>==</span><span>i</span><span>+</span><span>1</span><span>,:]</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
        <span>mean_vec</span> <span>=</span> <span>mean_vec</span><span>.</span><span>reshape</span><span>(</span><span>n_features</span><span>,</span> <span>1</span><span>)</span>
        <span>overall_mean</span> <span>=</span> <span>overall_mean</span><span>.</span><span>reshape</span><span>(</span><span>n_features</span><span>,</span> <span>1</span><span>)</span>
        <span>S_B</span> <span>+=</span> <span>n</span> <span>*</span> <span>(</span><span>mean_vec</span> <span>-</span> <span>overall_mean</span><span>)</span><span>.</span><span>dot</span><span>((</span><span>mean_vec</span> <span>-</span> <span>overall_mean</span><span>)</span><span>.</span><span>T</span><span>)</span>
    <span>return</span> <span>S_B</span>

<span>def</span> <span>get_components</span><span>(</span><span>eig_vals</span><span>,</span> <span>eig_vecs</span><span>,</span> <span>n_comp</span><span>=</span><span>2</span><span>):</span>
    <span>n_features</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>eig_pairs</span> <span>=</span> <span>[(</span><span>np</span><span>.</span><span>abs</span><span>(</span><span>eig_vals</span><span>[</span><span>i</span><span>]),</span> <span>eig_vecs</span><span>[:,</span><span>i</span><span>])</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span><span>eig_vals</span><span>))]</span>
    <span>eig_pairs</span> <span>=</span> <span>sorted</span><span>(</span><span>eig_pairs</span><span>,</span> <span>key</span><span>=</span><span>lambda</span> <span>k</span><span>:</span> <span>k</span><span>[</span><span>0</span><span>],</span> <span>reverse</span><span>=</span><span>True</span><span>)</span>
    <span>W</span> <span>=</span> <span>np</span><span>.</span><span>hstack</span><span>([</span><span>eig_pairs</span><span>[</span><span>i</span><span>][</span><span>1</span><span>]</span><span>.</span><span>reshape</span><span>(</span><span>4</span><span>,</span> <span>1</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>n_comp</span><span>)])</span>
    <span>return</span> <span>W</span>
</code></pre></div></div>

<p>First, we are going to print the eigenvalues, eigenvectors, transformation matrix of the un-scaled data:</p>

<div><div><pre><code><span>S_W</span><span>,</span> <span>S_B</span> <span>=</span> <span>scatter_within</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>),</span> <span>scatter_between</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>)</span>
<span>eig_vals</span><span>,</span> <span>eig_vecs</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>eig</span><span>(</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>inv</span><span>(</span><span>S_W</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>S_B</span><span>))</span>
<span>W</span> <span>=</span> <span>get_components</span><span>(</span><span>eig_vals</span><span>,</span> <span>eig_vecs</span><span>,</span> <span>n_comp</span><span>=</span><span>2</span><span>)</span>
<span>print</span><span>(</span><span>'EigVals: </span><span>%</span><span>s</span><span>\n\n</span><span>EigVecs: </span><span>%</span><span>s'</span> <span>%</span> <span>(</span><span>eig_vals</span><span>,</span> <span>eig_vecs</span><span>))</span>
<span>print</span><span>(</span><span>'</span><span>\n</span><span>W: </span><span>%</span><span>s'</span> <span>%</span> <span>W</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>EigVals: [  2.0905e+01 +0.0000e+00j   1.4283e-01 +0.0000e+00j
  -2.8680e-16 +1.9364e-15j  -2.8680e-16 -1.9364e-15j]

EigVecs: [[ 0.2067+0.j      0.0018+0.j      0.4846-0.4436j  0.4846+0.4436j]
 [ 0.4159+0.j     -0.5626+0.j      0.0599+0.1958j  0.0599-0.1958j]
 [-0.5616+0.j      0.2232+0.j      0.1194+0.1929j  0.1194-0.1929j]
 [-0.6848+0.j     -0.7960+0.j     -0.6892+0.j     -0.6892-0.j    ]]

W: [[ 0.2067+0.j  0.0018+0.j]
 [ 0.4159+0.j -0.5626+0.j]
 [-0.5616+0.j  0.2232+0.j]
 [-0.6848+0.j -0.7960+0.j]]
</code></pre></div></div>

<div><div><pre><code><span>X_lda</span> <span>=</span> <span>X</span><span>.</span><span>dot</span><span>(</span><span>W</span><span>)</span>
<span>for</span> <span>label</span><span>,</span><span>marker</span><span>,</span><span>color</span> <span>in</span> <span>zip</span><span>(</span>
        <span>np</span><span>.</span><span>unique</span><span>(</span><span>y</span><span>),(</span><span>'^'</span><span>,</span> <span>'s'</span><span>,</span> <span>'o'</span><span>),(</span><span>'blue'</span><span>,</span> <span>'red'</span><span>,</span> <span>'green'</span><span>)):</span>
    <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X_lda</span><span>[</span><span>y</span><span>==</span><span>label</span><span>,</span> <span>0</span><span>],</span> <span>X_lda</span><span>[</span><span>y</span><span>==</span><span>label</span><span>,</span> <span>1</span><span>],</span>
                <span>color</span><span>=</span><span>color</span><span>,</span> <span>marker</span><span>=</span><span>marker</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>/Users/sebastian/miniconda3/lib/python3.5/site-packages/numpy/core/numeric.py:525: ComplexWarning: Casting complex values to real discards the imaginary part
  return array(a, dtype, copy=False, order=order, subok=True)
</code></pre></div></div>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_154_1.png" alt="png"></p>

<p>Next, we are repeating this process for the standarized flower dataset:</p>

<div><div><pre><code><span>S_W</span><span>,</span> <span>S_B</span> <span>=</span> <span>scatter_within</span><span>(</span><span>X_std</span><span>,</span> <span>y</span><span>),</span> <span>scatter_between</span><span>(</span><span>X_std</span><span>,</span> <span>y</span><span>)</span>
<span>eig_vals</span><span>,</span> <span>eig_vecs</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>eig</span><span>(</span><span>np</span><span>.</span><span>linalg</span><span>.</span><span>inv</span><span>(</span><span>S_W</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>S_B</span><span>))</span>
<span>W_std</span> <span>=</span> <span>get_components</span><span>(</span><span>eig_vals</span><span>,</span> <span>eig_vecs</span><span>,</span> <span>n_comp</span><span>=</span><span>2</span><span>)</span>
<span>print</span><span>(</span><span>'EigVals: </span><span>%</span><span>s</span><span>\n\n</span><span>EigVecs: </span><span>%</span><span>s'</span> <span>%</span> <span>(</span><span>eig_vals</span><span>,</span> <span>eig_vecs</span><span>))</span>
<span>print</span><span>(</span><span>'</span><span>\n</span><span>W: </span><span>%</span><span>s'</span> <span>%</span> <span>W_std</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>EigVals: [  2.0905e+01   1.4283e-01  -6.7207e-16   1.1082e-15]

EigVecs: [[ 0.1492 -0.0019  0.8194 -0.3704]
 [ 0.1572  0.3193 -0.1382 -0.0884]
 [-0.8635 -0.5155 -0.5078 -0.5106]
 [-0.4554  0.7952 -0.2271  0.7709]]

W: [[ 0.1492 -0.0019]
 [ 0.1572  0.3193]
 [-0.8635 -0.5155]
 [-0.4554  0.7952]]
</code></pre></div></div>

<div><div><pre><code><span>X_std_lda</span> <span>=</span> <span>X_std</span><span>.</span><span>dot</span><span>(</span><span>W_std</span><span>)</span>
<span>X_std_lda</span><span>[:,</span> <span>1</span><span>]</span> <span>=</span> <span>X_std_lda</span><span>[:,</span> <span>1</span><span>]</span>
<span>for</span> <span>label</span><span>,</span><span>marker</span><span>,</span><span>color</span> <span>in</span> <span>zip</span><span>(</span>
        <span>np</span><span>.</span><span>unique</span><span>(</span><span>y</span><span>),(</span><span>'^'</span><span>,</span> <span>'s'</span><span>,</span> <span>'o'</span><span>),(</span><span>'blue'</span><span>,</span> <span>'red'</span><span>,</span> <span>'green'</span><span>)):</span>
    <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X_std_lda</span><span>[</span><span>y</span><span>==</span><span>label</span><span>,</span> <span>0</span><span>],</span> <span>X_std_lda</span><span>[</span><span>y</span><span>==</span><span>label</span><span>,</span> <span>1</span><span>],</span>
                <span>color</span><span>=</span><span>color</span><span>,</span> <span>marker</span><span>=</span><span>marker</span><span>)</span>
</code></pre></div></div>

<p><img src="Linear%20Discriminant%20Analysis_files/2014-08-03-linear_discriminant_analysis_157_0.png" alt="png"></p>

<p>As we can see, the eigenvalues are excactly the same whether we scaled our data or not (note that since <span id="MathJax-Element-79-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span id="MathJax-Span-1364"><span><span><span id="MathJax-Span-1365"><span id="MathJax-Span-1366">W<span></span></span></span><span></span></span></span><span></span></span></nobr><span role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></span></span>
 has a rank of 2, the two lowest eigenvalues in this 4-dimensional 
dataset should effectively be 0). Furthermore, we see that the 
projections look identical except for the different scaling of the 
component axes and that it is mirrored in this case.</p>

  </article>




</div>


      </div>
    </div></div></div>
    </div>

    <div>
      <div class="reader-message">Loading…</div>
    </div>
  </div>

  <ul class="toolbar reader-toolbar">
    <li><button class="button close-button" title="Close Reader View"></button></li>
    <ul class="dropdown style-dropdown">
      <li><button class="dropdown-toggle button style-button" title="Type controls"></button></li>
      <li class="dropdown-popup">
        <div class="font-type-buttons"><button class="sans-serif-button selected"><div class="name">Aa</div><div class="description">Sans-serif</div></button><button class="serif-button"><div class="name">Aa</div><div class="description">Serif</div></button></div>
        <hr>
        <div class="font-size-buttons">
          <button class="minus-button">
          </button><button class="font-size-sample">Aa</button><button class="plus-button">
        </button></div>
        <hr>
        <div class="content-width-buttons">
          <button class="content-width-minus-button">
          </button><button class="content-width-plus-button">
        </button></div>
        <hr>
        <div class="line-height-buttons">
          <button class="line-height-minus-button">
          </button><button class="line-height-plus-button">
        </button></div>
        <hr>
        <div class="color-scheme-buttons"><button class="light-button selected"><div class="name">Light</div></button><button class="dark-button"><div class="name">Dark</div></button><button class="sepia-button"><div class="name">Sepia</div></button></div>
        <div class="dropdown-arrow">
      </div></li>
    </ul>
  <ul class="dropdown narrate-dropdown"><li>
       <button class="dropdown-toggle button narrate-toggle" title="Narrate"></button>
    </li>
    <li class="dropdown-popup">
      <div class="narrate-row narrate-control">
        <button disabled="disabled" class="narrate-skip-previous" title="Back"></button>
        <button class="narrate-start-stop" title="Start"></button>
        <button disabled="disabled" class="narrate-skip-next" title="Forward"></button>
      </div>
      <div class="narrate-row narrate-rate">
        <input class="narrate-rate-input" value="0" step="5" max="100" min="-100" type="range" title="Speed">
      </div>
      <div class="narrate-row narrate-voices"><div class="voiceselect voice-select"><button class="select-toggle" aria-controls="voice-options">
      <span class="label">Voice:</span> <span class="current-voice">Default</span>
    </button>
    <div class="options" id="voice-options" role="listbox"><button data-value="automatic" class="option selected" tabindex="-1" role="option" aria-selected="true">Default</button><button data-value="urn:moz-tts:speechd:English_(Caribbean)?en-029" class="option" tabindex="-1" role="option">English (en-029)</button><button data-value="urn:moz-tts:speechd:English_(Lancaster)?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:English_(Received_Pronunciation)?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:English_(West_Midlands)?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:English_(Great_Britain)?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:English_(Scotland)?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:English_(America)?en-US" class="option" tabindex="-1" role="option">English (en-US)</button></div></div></div>
      <div class="dropdown-arrow"></div>
    </li></ul><button data-buttonid="pocket-button" class="button pocket-button" style="background-image: url(&quot;chrome://pocket/content/panels/img/pocket-outline.svg&quot;); background-size: 20px 20px;" title="Save to Pocket"></button></ul>




</body></html>